{"ast":null,"code":"import _slicedToArray from \"/Users/yinger/Desktop/algo_evaluator_front/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";\nimport _createForOfIteratorHelper from \"/Users/yinger/Desktop/algo_evaluator_front/node_modules/@babel/runtime/helpers/esm/createForOfIteratorHelper.js\";\nimport _callSuper from \"/Users/yinger/Desktop/algo_evaluator_front/node_modules/@babel/runtime/helpers/esm/callSuper.js\";\nimport _inherits from \"/Users/yinger/Desktop/algo_evaluator_front/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _classCallCheck from \"/Users/yinger/Desktop/algo_evaluator_front/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"/Users/yinger/Desktop/algo_evaluator_front/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport \"core-js/modules/es.error.to-string.js\";\nimport \"core-js/modules/es.array.find-index.js\";\nimport \"core-js/modules/es.array.join.js\";\nimport \"core-js/modules/es.array.map.js\";\nimport \"core-js/modules/es.array.push.js\";\nimport \"core-js/modules/es.array.reverse.js\";\nimport \"core-js/modules/es.array.splice.js\";\nimport \"core-js/modules/es.date.now.js\";\nimport \"core-js/modules/es.date.to-string.js\";\nimport \"core-js/modules/es.number.max-safe-integer.js\";\nimport \"core-js/modules/es.object.to-string.js\";\nimport \"core-js/modules/es.regexp.exec.js\";\nimport \"core-js/modules/es.regexp.to-string.js\";\nimport \"core-js/modules/es.string.replace.js\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport { runWhenGlobalIdle } from '../../../base/common/async.js';\nimport { BugIndicatingError, onUnexpectedError } from '../../../base/common/errors.js';\nimport { setTimeout0 } from '../../../base/common/platform.js';\nimport { StopWatch } from '../../../base/common/stopwatch.js';\nimport { countEOL } from '../core/eolCounter.js';\nimport { LineRange } from '../core/lineRange.js';\nimport { OffsetRange } from '../core/offsetRange.js';\nimport { nullTokenizeEncoded } from '../languages/nullTokenize.js';\nimport { FixedArray } from './fixedArray.js';\nimport { ContiguousMultilineTokensBuilder } from '../tokens/contiguousMultilineTokensBuilder.js';\nimport { LineTokens } from '../tokens/lineTokens.js';\nexport var TokenizerWithStateStore = /*#__PURE__*/function () {\n  function TokenizerWithStateStore(lineCount, tokenizationSupport) {\n    _classCallCheck(this, TokenizerWithStateStore);\n    this.tokenizationSupport = tokenizationSupport;\n    this.initialState = this.tokenizationSupport.getInitialState();\n    this.store = new TrackingTokenizationStateStore(lineCount);\n  }\n  return _createClass(TokenizerWithStateStore, [{\n    key: \"getStartState\",\n    value: function getStartState(lineNumber) {\n      return this.store.getStartState(lineNumber, this.initialState);\n    }\n  }, {\n    key: \"getFirstInvalidLine\",\n    value: function getFirstInvalidLine() {\n      return this.store.getFirstInvalidLine(this.initialState);\n    }\n  }]);\n}();\nexport var TokenizerWithStateStoreAndTextModel = /*#__PURE__*/function (_TokenizerWithStateSt) {\n  function TokenizerWithStateStoreAndTextModel(lineCount, tokenizationSupport, _textModel, _languageIdCodec) {\n    var _this;\n    _classCallCheck(this, TokenizerWithStateStoreAndTextModel);\n    _this = _callSuper(this, TokenizerWithStateStoreAndTextModel, [lineCount, tokenizationSupport]);\n    _this._textModel = _textModel;\n    _this._languageIdCodec = _languageIdCodec;\n    return _this;\n  }\n  _inherits(TokenizerWithStateStoreAndTextModel, _TokenizerWithStateSt);\n  return _createClass(TokenizerWithStateStoreAndTextModel, [{\n    key: \"updateTokensUntilLine\",\n    value: function updateTokensUntilLine(builder, lineNumber) {\n      var languageId = this._textModel.getLanguageId();\n      while (true) {\n        var lineToTokenize = this.getFirstInvalidLine();\n        if (!lineToTokenize || lineToTokenize.lineNumber > lineNumber) {\n          break;\n        }\n        var text = this._textModel.getLineContent(lineToTokenize.lineNumber);\n        var r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, text, true, lineToTokenize.startState);\n        builder.add(lineToTokenize.lineNumber, r.tokens);\n        this.store.setEndState(lineToTokenize.lineNumber, r.endState);\n      }\n    }\n    /** assumes state is up to date */\n  }, {\n    key: \"getTokenTypeIfInsertingCharacter\",\n    value: function getTokenTypeIfInsertingCharacter(position, character) {\n      // TODO@hediet: use tokenizeLineWithEdit\n      var lineStartState = this.getStartState(position.lineNumber);\n      if (!lineStartState) {\n        return 0 /* StandardTokenType.Other */;\n      }\n      var languageId = this._textModel.getLanguageId();\n      var lineContent = this._textModel.getLineContent(position.lineNumber);\n      // Create the text as if `character` was inserted\n      var text = lineContent.substring(0, position.column - 1) + character + lineContent.substring(position.column - 1);\n      var r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, text, true, lineStartState);\n      var lineTokens = new LineTokens(r.tokens, text, this._languageIdCodec);\n      if (lineTokens.getCount() === 0) {\n        return 0 /* StandardTokenType.Other */;\n      }\n      var tokenIndex = lineTokens.findTokenIndexAtOffset(position.column - 1);\n      return lineTokens.getStandardTokenType(tokenIndex);\n    }\n    /** assumes state is up to date */\n  }, {\n    key: \"tokenizeLineWithEdit\",\n    value: function tokenizeLineWithEdit(position, length, newText) {\n      var lineNumber = position.lineNumber;\n      var column = position.column;\n      var lineStartState = this.getStartState(lineNumber);\n      if (!lineStartState) {\n        return null;\n      }\n      var curLineContent = this._textModel.getLineContent(lineNumber);\n      var newLineContent = curLineContent.substring(0, column - 1) + newText + curLineContent.substring(column - 1 + length);\n      var languageId = this._textModel.getLanguageIdAtPosition(lineNumber, 0);\n      var result = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, newLineContent, true, lineStartState);\n      var lineTokens = new LineTokens(result.tokens, newLineContent, this._languageIdCodec);\n      return lineTokens;\n    }\n  }, {\n    key: \"hasAccurateTokensForLine\",\n    value: function hasAccurateTokensForLine(lineNumber) {\n      var firstInvalidLineNumber = this.store.getFirstInvalidEndStateLineNumberOrMax();\n      return lineNumber < firstInvalidLineNumber;\n    }\n  }, {\n    key: \"isCheapToTokenize\",\n    value: function isCheapToTokenize(lineNumber) {\n      var firstInvalidLineNumber = this.store.getFirstInvalidEndStateLineNumberOrMax();\n      if (lineNumber < firstInvalidLineNumber) {\n        return true;\n      }\n      if (lineNumber === firstInvalidLineNumber && this._textModel.getLineLength(lineNumber) < 2048 /* Constants.CHEAP_TOKENIZATION_LENGTH_LIMIT */) {\n        return true;\n      }\n      return false;\n    }\n    /**\n     * The result is not cached.\n     */\n  }, {\n    key: \"tokenizeHeuristically\",\n    value: function tokenizeHeuristically(builder, startLineNumber, endLineNumber) {\n      if (endLineNumber <= this.store.getFirstInvalidEndStateLineNumberOrMax()) {\n        // nothing to do\n        return {\n          heuristicTokens: false\n        };\n      }\n      if (startLineNumber <= this.store.getFirstInvalidEndStateLineNumberOrMax()) {\n        // tokenization has reached the viewport start...\n        this.updateTokensUntilLine(builder, endLineNumber);\n        return {\n          heuristicTokens: false\n        };\n      }\n      var state = this.guessStartState(startLineNumber);\n      var languageId = this._textModel.getLanguageId();\n      for (var lineNumber = startLineNumber; lineNumber <= endLineNumber; lineNumber++) {\n        var text = this._textModel.getLineContent(lineNumber);\n        var r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, text, true, state);\n        builder.add(lineNumber, r.tokens);\n        state = r.endState;\n      }\n      return {\n        heuristicTokens: true\n      };\n    }\n  }, {\n    key: \"guessStartState\",\n    value: function guessStartState(lineNumber) {\n      var nonWhitespaceColumn = this._textModel.getLineFirstNonWhitespaceColumn(lineNumber);\n      var likelyRelevantLines = [];\n      var initialState = null;\n      for (var i = lineNumber - 1; nonWhitespaceColumn > 1 && i >= 1; i--) {\n        var newNonWhitespaceIndex = this._textModel.getLineFirstNonWhitespaceColumn(i);\n        // Ignore lines full of whitespace\n        if (newNonWhitespaceIndex === 0) {\n          continue;\n        }\n        if (newNonWhitespaceIndex < nonWhitespaceColumn) {\n          likelyRelevantLines.push(this._textModel.getLineContent(i));\n          nonWhitespaceColumn = newNonWhitespaceIndex;\n          initialState = this.getStartState(i);\n          if (initialState) {\n            break;\n          }\n        }\n      }\n      if (!initialState) {\n        initialState = this.tokenizationSupport.getInitialState();\n      }\n      likelyRelevantLines.reverse();\n      var languageId = this._textModel.getLanguageId();\n      var state = initialState;\n      for (var _i = 0, _likelyRelevantLines = likelyRelevantLines; _i < _likelyRelevantLines.length; _i++) {\n        var line = _likelyRelevantLines[_i];\n        var r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, line, false, state);\n        state = r.endState;\n      }\n      return state;\n    }\n  }]);\n}(TokenizerWithStateStore);\n/**\n * **Invariant:**\n * If the text model is retokenized from line 1 to {@link getFirstInvalidEndStateLineNumber}() - 1,\n * then the recomputed end state for line l will be equal to {@link getEndState}(l).\n */\nexport var TrackingTokenizationStateStore = /*#__PURE__*/function () {\n  function TrackingTokenizationStateStore(lineCount) {\n    _classCallCheck(this, TrackingTokenizationStateStore);\n    this.lineCount = lineCount;\n    this._tokenizationStateStore = new TokenizationStateStore();\n    this._invalidEndStatesLineNumbers = new RangePriorityQueueImpl();\n    this._invalidEndStatesLineNumbers.addRange(new OffsetRange(1, lineCount + 1));\n  }\n  return _createClass(TrackingTokenizationStateStore, [{\n    key: \"getEndState\",\n    value: function getEndState(lineNumber) {\n      return this._tokenizationStateStore.getEndState(lineNumber);\n    }\n    /**\n     * @returns if the end state has changed.\n     */\n  }, {\n    key: \"setEndState\",\n    value: function setEndState(lineNumber, state) {\n      if (!state) {\n        throw new BugIndicatingError('Cannot set null/undefined state');\n      }\n      this._invalidEndStatesLineNumbers[\"delete\"](lineNumber);\n      var r = this._tokenizationStateStore.setEndState(lineNumber, state);\n      if (r && lineNumber < this.lineCount) {\n        // because the state changed, we cannot trust the next state anymore and have to invalidate it.\n        this._invalidEndStatesLineNumbers.addRange(new OffsetRange(lineNumber + 1, lineNumber + 2));\n      }\n      return r;\n    }\n  }, {\n    key: \"acceptChange\",\n    value: function acceptChange(range, newLineCount) {\n      this.lineCount += newLineCount - range.length;\n      this._tokenizationStateStore.acceptChange(range, newLineCount);\n      this._invalidEndStatesLineNumbers.addRangeAndResize(new OffsetRange(range.startLineNumber, range.endLineNumberExclusive), newLineCount);\n    }\n  }, {\n    key: \"acceptChanges\",\n    value: function acceptChanges(changes) {\n      var _iterator = _createForOfIteratorHelper(changes),\n        _step;\n      try {\n        for (_iterator.s(); !(_step = _iterator.n()).done;) {\n          var c = _step.value;\n          var _countEOL = countEOL(c.text),\n            _countEOL2 = _slicedToArray(_countEOL, 1),\n            eolCount = _countEOL2[0];\n          this.acceptChange(new LineRange(c.range.startLineNumber, c.range.endLineNumber + 1), eolCount + 1);\n        }\n      } catch (err) {\n        _iterator.e(err);\n      } finally {\n        _iterator.f();\n      }\n    }\n  }, {\n    key: \"invalidateEndStateRange\",\n    value: function invalidateEndStateRange(range) {\n      this._invalidEndStatesLineNumbers.addRange(new OffsetRange(range.startLineNumber, range.endLineNumberExclusive));\n    }\n  }, {\n    key: \"getFirstInvalidEndStateLineNumber\",\n    value: function getFirstInvalidEndStateLineNumber() {\n      return this._invalidEndStatesLineNumbers.min;\n    }\n  }, {\n    key: \"getFirstInvalidEndStateLineNumberOrMax\",\n    value: function getFirstInvalidEndStateLineNumberOrMax() {\n      return this.getFirstInvalidEndStateLineNumber() || Number.MAX_SAFE_INTEGER;\n    }\n  }, {\n    key: \"allStatesValid\",\n    value: function allStatesValid() {\n      return this._invalidEndStatesLineNumbers.min === null;\n    }\n  }, {\n    key: \"getStartState\",\n    value: function getStartState(lineNumber, initialState) {\n      if (lineNumber === 1) {\n        return initialState;\n      }\n      return this.getEndState(lineNumber - 1);\n    }\n  }, {\n    key: \"getFirstInvalidLine\",\n    value: function getFirstInvalidLine(initialState) {\n      var lineNumber = this.getFirstInvalidEndStateLineNumber();\n      if (lineNumber === null) {\n        return null;\n      }\n      var startState = this.getStartState(lineNumber, initialState);\n      if (!startState) {\n        throw new BugIndicatingError('Start state must be defined');\n      }\n      return {\n        lineNumber: lineNumber,\n        startState: startState\n      };\n    }\n  }]);\n}();\nexport var TokenizationStateStore = /*#__PURE__*/function () {\n  function TokenizationStateStore() {\n    _classCallCheck(this, TokenizationStateStore);\n    this._lineEndStates = new FixedArray(null);\n  }\n  return _createClass(TokenizationStateStore, [{\n    key: \"getEndState\",\n    value: function getEndState(lineNumber) {\n      return this._lineEndStates.get(lineNumber);\n    }\n  }, {\n    key: \"setEndState\",\n    value: function setEndState(lineNumber, state) {\n      var oldState = this._lineEndStates.get(lineNumber);\n      if (oldState && oldState.equals(state)) {\n        return false;\n      }\n      this._lineEndStates.set(lineNumber, state);\n      return true;\n    }\n  }, {\n    key: \"acceptChange\",\n    value: function acceptChange(range, newLineCount) {\n      var length = range.length;\n      if (newLineCount > 0 && length > 0) {\n        // Keep the last state, even though it is unrelated.\n        // But if the new state happens to agree with this last state, then we know we can stop tokenizing.\n        length--;\n        newLineCount--;\n      }\n      this._lineEndStates.replace(range.startLineNumber, length, newLineCount);\n    }\n  }]);\n}();\nexport var RangePriorityQueueImpl = /*#__PURE__*/function () {\n  function RangePriorityQueueImpl() {\n    _classCallCheck(this, RangePriorityQueueImpl);\n    this._ranges = [];\n  }\n  return _createClass(RangePriorityQueueImpl, [{\n    key: \"min\",\n    get: function get() {\n      if (this._ranges.length === 0) {\n        return null;\n      }\n      return this._ranges[0].start;\n    }\n  }, {\n    key: \"delete\",\n    value: function _delete(value) {\n      var idx = this._ranges.findIndex(function (r) {\n        return r.contains(value);\n      });\n      if (idx !== -1) {\n        var range = this._ranges[idx];\n        if (range.start === value) {\n          if (range.endExclusive === value + 1) {\n            this._ranges.splice(idx, 1);\n          } else {\n            this._ranges[idx] = new OffsetRange(value + 1, range.endExclusive);\n          }\n        } else {\n          if (range.endExclusive === value + 1) {\n            this._ranges[idx] = new OffsetRange(range.start, value);\n          } else {\n            this._ranges.splice(idx, 1, new OffsetRange(range.start, value), new OffsetRange(value + 1, range.endExclusive));\n          }\n        }\n      }\n    }\n  }, {\n    key: \"addRange\",\n    value: function addRange(range) {\n      OffsetRange.addRange(range, this._ranges);\n    }\n  }, {\n    key: \"addRangeAndResize\",\n    value: function addRangeAndResize(range, newLength) {\n      var idxFirstMightBeIntersecting = 0;\n      while (!(idxFirstMightBeIntersecting >= this._ranges.length || range.start <= this._ranges[idxFirstMightBeIntersecting].endExclusive)) {\n        idxFirstMightBeIntersecting++;\n      }\n      var idxFirstIsAfter = idxFirstMightBeIntersecting;\n      while (!(idxFirstIsAfter >= this._ranges.length || range.endExclusive < this._ranges[idxFirstIsAfter].start)) {\n        idxFirstIsAfter++;\n      }\n      var delta = newLength - range.length;\n      for (var i = idxFirstIsAfter; i < this._ranges.length; i++) {\n        this._ranges[i] = this._ranges[i].delta(delta);\n      }\n      if (idxFirstMightBeIntersecting === idxFirstIsAfter) {\n        var newRange = new OffsetRange(range.start, range.start + newLength);\n        if (!newRange.isEmpty) {\n          this._ranges.splice(idxFirstMightBeIntersecting, 0, newRange);\n        }\n      } else {\n        var start = Math.min(range.start, this._ranges[idxFirstMightBeIntersecting].start);\n        var endEx = Math.max(range.endExclusive, this._ranges[idxFirstIsAfter - 1].endExclusive);\n        var _newRange = new OffsetRange(start, endEx + delta);\n        if (!_newRange.isEmpty) {\n          this._ranges.splice(idxFirstMightBeIntersecting, idxFirstIsAfter - idxFirstMightBeIntersecting, _newRange);\n        } else {\n          this._ranges.splice(idxFirstMightBeIntersecting, idxFirstIsAfter - idxFirstMightBeIntersecting);\n        }\n      }\n    }\n  }, {\n    key: \"toString\",\n    value: function toString() {\n      return this._ranges.map(function (r) {\n        return r.toString();\n      }).join(' + ');\n    }\n  }]);\n}();\nfunction safeTokenize(languageIdCodec, languageId, tokenizationSupport, text, hasEOL, state) {\n  var r = null;\n  if (tokenizationSupport) {\n    try {\n      r = tokenizationSupport.tokenizeEncoded(text, hasEOL, state.clone());\n    } catch (e) {\n      onUnexpectedError(e);\n    }\n  }\n  if (!r) {\n    r = nullTokenizeEncoded(languageIdCodec.encodeLanguageId(languageId), state);\n  }\n  LineTokens.convertToEndOffset(r.tokens, text.length);\n  return r;\n}\nexport var DefaultBackgroundTokenizer = /*#__PURE__*/function () {\n  function DefaultBackgroundTokenizer(_tokenizerWithStateStore, _backgroundTokenStore) {\n    _classCallCheck(this, DefaultBackgroundTokenizer);\n    this._tokenizerWithStateStore = _tokenizerWithStateStore;\n    this._backgroundTokenStore = _backgroundTokenStore;\n    this._isDisposed = false;\n    this._isScheduled = false;\n  }\n  return _createClass(DefaultBackgroundTokenizer, [{\n    key: \"dispose\",\n    value: function dispose() {\n      this._isDisposed = true;\n    }\n  }, {\n    key: \"handleChanges\",\n    value: function handleChanges() {\n      this._beginBackgroundTokenization();\n    }\n  }, {\n    key: \"_beginBackgroundTokenization\",\n    value: function _beginBackgroundTokenization() {\n      var _this2 = this;\n      if (this._isScheduled || !this._tokenizerWithStateStore._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n        return;\n      }\n      this._isScheduled = true;\n      runWhenGlobalIdle(function (deadline) {\n        _this2._isScheduled = false;\n        _this2._backgroundTokenizeWithDeadline(deadline);\n      });\n    }\n    /**\n     * Tokenize until the deadline occurs, but try to yield every 1-2ms.\n     */\n  }, {\n    key: \"_backgroundTokenizeWithDeadline\",\n    value: function _backgroundTokenizeWithDeadline(deadline) {\n      var _this3 = this;\n      // Read the time remaining from the `deadline` immediately because it is unclear\n      // if the `deadline` object will be valid after execution leaves this function.\n      var endTime = Date.now() + deadline.timeRemaining();\n      var execute = function execute() {\n        if (_this3._isDisposed || !_this3._tokenizerWithStateStore._textModel.isAttachedToEditor() || !_this3._hasLinesToTokenize()) {\n          // disposed in the meantime or detached or finished\n          return;\n        }\n        _this3._backgroundTokenizeForAtLeast1ms();\n        if (Date.now() < endTime) {\n          // There is still time before reaching the deadline, so yield to the browser and then\n          // continue execution\n          setTimeout0(execute);\n        } else {\n          // The deadline has been reached, so schedule a new idle callback if necessary\n          _this3._beginBackgroundTokenization();\n        }\n      };\n      execute();\n    }\n    /**\n     * Tokenize for at least 1ms.\n     */\n  }, {\n    key: \"_backgroundTokenizeForAtLeast1ms\",\n    value: function _backgroundTokenizeForAtLeast1ms() {\n      var lineCount = this._tokenizerWithStateStore._textModel.getLineCount();\n      var builder = new ContiguousMultilineTokensBuilder();\n      var sw = StopWatch.create(false);\n      do {\n        if (sw.elapsed() > 1) {\n          // the comparison is intentionally > 1 and not >= 1 to ensure that\n          // a full millisecond has elapsed, given how microseconds are rounded\n          // to milliseconds\n          break;\n        }\n        var tokenizedLineNumber = this._tokenizeOneInvalidLine(builder);\n        if (tokenizedLineNumber >= lineCount) {\n          break;\n        }\n      } while (this._hasLinesToTokenize());\n      this._backgroundTokenStore.setTokens(builder.finalize());\n      this.checkFinished();\n    }\n  }, {\n    key: \"_hasLinesToTokenize\",\n    value: function _hasLinesToTokenize() {\n      if (!this._tokenizerWithStateStore) {\n        return false;\n      }\n      return !this._tokenizerWithStateStore.store.allStatesValid();\n    }\n  }, {\n    key: \"_tokenizeOneInvalidLine\",\n    value: function _tokenizeOneInvalidLine(builder) {\n      var _a;\n      var firstInvalidLine = (_a = this._tokenizerWithStateStore) === null || _a === void 0 ? void 0 : _a.getFirstInvalidLine();\n      if (!firstInvalidLine) {\n        return this._tokenizerWithStateStore._textModel.getLineCount() + 1;\n      }\n      this._tokenizerWithStateStore.updateTokensUntilLine(builder, firstInvalidLine.lineNumber);\n      return firstInvalidLine.lineNumber;\n    }\n  }, {\n    key: \"checkFinished\",\n    value: function checkFinished() {\n      if (this._isDisposed) {\n        return;\n      }\n      if (this._tokenizerWithStateStore.store.allStatesValid()) {\n        this._backgroundTokenStore.backgroundTokenizationFinished();\n      }\n    }\n  }, {\n    key: \"requestTokens\",\n    value: function requestTokens(startLineNumber, endLineNumberExclusive) {\n      this._tokenizerWithStateStore.store.invalidateEndStateRange(new LineRange(startLineNumber, endLineNumberExclusive));\n    }\n  }]);\n}();","map":{"version":3,"names":["runWhenGlobalIdle","BugIndicatingError","onUnexpectedError","setTimeout0","StopWatch","countEOL","LineRange","OffsetRange","nullTokenizeEncoded","FixedArray","ContiguousMultilineTokensBuilder","LineTokens","TokenizerWithStateStore","lineCount","tokenizationSupport","_classCallCheck","initialState","getInitialState","store","TrackingTokenizationStateStore","_createClass","key","value","getStartState","lineNumber","getFirstInvalidLine","TokenizerWithStateStoreAndTextModel","_TokenizerWithStateSt","_textModel","_languageIdCodec","_this","_callSuper","_inherits","updateTokensUntilLine","builder","languageId","getLanguageId","lineToTokenize","text","getLineContent","r","safeTokenize","startState","add","tokens","setEndState","endState","getTokenTypeIfInsertingCharacter","position","character","lineStartState","lineContent","substring","column","lineTokens","getCount","tokenIndex","findTokenIndexAtOffset","getStandardTokenType","tokenizeLineWithEdit","length","newText","curLineContent","newLineContent","getLanguageIdAtPosition","result","hasAccurateTokensForLine","firstInvalidLineNumber","getFirstInvalidEndStateLineNumberOrMax","isCheapToTokenize","getLineLength","tokenizeHeuristically","startLineNumber","endLineNumber","heuristicTokens","state","guessStartState","nonWhitespaceColumn","getLineFirstNonWhitespaceColumn","likelyRelevantLines","i","newNonWhitespaceIndex","push","reverse","_i","_likelyRelevantLines","line","_tokenizationStateStore","TokenizationStateStore","_invalidEndStatesLineNumbers","RangePriorityQueueImpl","addRange","getEndState","acceptChange","range","newLineCount","addRangeAndResize","endLineNumberExclusive","acceptChanges","changes","_iterator","_createForOfIteratorHelper","_step","s","n","done","c","_countEOL","_countEOL2","_slicedToArray","eolCount","err","e","f","invalidateEndStateRange","getFirstInvalidEndStateLineNumber","min","Number","MAX_SAFE_INTEGER","allStatesValid","_lineEndStates","get","oldState","equals","set","replace","_ranges","start","_delete","idx","findIndex","contains","endExclusive","splice","newLength","idxFirstMightBeIntersecting","idxFirstIsAfter","delta","newRange","isEmpty","Math","endEx","max","toString","map","join","languageIdCodec","hasEOL","tokenizeEncoded","clone","encodeLanguageId","convertToEndOffset","DefaultBackgroundTokenizer","_tokenizerWithStateStore","_backgroundTokenStore","_isDisposed","_isScheduled","dispose","handleChanges","_beginBackgroundTokenization","_this2","isAttachedToEditor","_hasLinesToTokenize","deadline","_backgroundTokenizeWithDeadline","_this3","endTime","Date","now","timeRemaining","execute","_backgroundTokenizeForAtLeast1ms","getLineCount","sw","create","elapsed","tokenizedLineNumber","_tokenizeOneInvalidLine","setTokens","finalize","checkFinished","_a","firstInvalidLine","backgroundTokenizationFinished","requestTokens"],"sources":["/Users/yinger/Desktop/algo_evaluator_front/node_modules/monaco-editor/esm/vs/editor/common/model/textModelTokens.js"],"sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport { runWhenGlobalIdle } from '../../../base/common/async.js';\nimport { BugIndicatingError, onUnexpectedError } from '../../../base/common/errors.js';\nimport { setTimeout0 } from '../../../base/common/platform.js';\nimport { StopWatch } from '../../../base/common/stopwatch.js';\nimport { countEOL } from '../core/eolCounter.js';\nimport { LineRange } from '../core/lineRange.js';\nimport { OffsetRange } from '../core/offsetRange.js';\nimport { nullTokenizeEncoded } from '../languages/nullTokenize.js';\nimport { FixedArray } from './fixedArray.js';\nimport { ContiguousMultilineTokensBuilder } from '../tokens/contiguousMultilineTokensBuilder.js';\nimport { LineTokens } from '../tokens/lineTokens.js';\nexport class TokenizerWithStateStore {\n    constructor(lineCount, tokenizationSupport) {\n        this.tokenizationSupport = tokenizationSupport;\n        this.initialState = this.tokenizationSupport.getInitialState();\n        this.store = new TrackingTokenizationStateStore(lineCount);\n    }\n    getStartState(lineNumber) {\n        return this.store.getStartState(lineNumber, this.initialState);\n    }\n    getFirstInvalidLine() {\n        return this.store.getFirstInvalidLine(this.initialState);\n    }\n}\nexport class TokenizerWithStateStoreAndTextModel extends TokenizerWithStateStore {\n    constructor(lineCount, tokenizationSupport, _textModel, _languageIdCodec) {\n        super(lineCount, tokenizationSupport);\n        this._textModel = _textModel;\n        this._languageIdCodec = _languageIdCodec;\n    }\n    updateTokensUntilLine(builder, lineNumber) {\n        const languageId = this._textModel.getLanguageId();\n        while (true) {\n            const lineToTokenize = this.getFirstInvalidLine();\n            if (!lineToTokenize || lineToTokenize.lineNumber > lineNumber) {\n                break;\n            }\n            const text = this._textModel.getLineContent(lineToTokenize.lineNumber);\n            const r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, text, true, lineToTokenize.startState);\n            builder.add(lineToTokenize.lineNumber, r.tokens);\n            this.store.setEndState(lineToTokenize.lineNumber, r.endState);\n        }\n    }\n    /** assumes state is up to date */\n    getTokenTypeIfInsertingCharacter(position, character) {\n        // TODO@hediet: use tokenizeLineWithEdit\n        const lineStartState = this.getStartState(position.lineNumber);\n        if (!lineStartState) {\n            return 0 /* StandardTokenType.Other */;\n        }\n        const languageId = this._textModel.getLanguageId();\n        const lineContent = this._textModel.getLineContent(position.lineNumber);\n        // Create the text as if `character` was inserted\n        const text = (lineContent.substring(0, position.column - 1)\n            + character\n            + lineContent.substring(position.column - 1));\n        const r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, text, true, lineStartState);\n        const lineTokens = new LineTokens(r.tokens, text, this._languageIdCodec);\n        if (lineTokens.getCount() === 0) {\n            return 0 /* StandardTokenType.Other */;\n        }\n        const tokenIndex = lineTokens.findTokenIndexAtOffset(position.column - 1);\n        return lineTokens.getStandardTokenType(tokenIndex);\n    }\n    /** assumes state is up to date */\n    tokenizeLineWithEdit(position, length, newText) {\n        const lineNumber = position.lineNumber;\n        const column = position.column;\n        const lineStartState = this.getStartState(lineNumber);\n        if (!lineStartState) {\n            return null;\n        }\n        const curLineContent = this._textModel.getLineContent(lineNumber);\n        const newLineContent = curLineContent.substring(0, column - 1)\n            + newText + curLineContent.substring(column - 1 + length);\n        const languageId = this._textModel.getLanguageIdAtPosition(lineNumber, 0);\n        const result = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, newLineContent, true, lineStartState);\n        const lineTokens = new LineTokens(result.tokens, newLineContent, this._languageIdCodec);\n        return lineTokens;\n    }\n    hasAccurateTokensForLine(lineNumber) {\n        const firstInvalidLineNumber = this.store.getFirstInvalidEndStateLineNumberOrMax();\n        return (lineNumber < firstInvalidLineNumber);\n    }\n    isCheapToTokenize(lineNumber) {\n        const firstInvalidLineNumber = this.store.getFirstInvalidEndStateLineNumberOrMax();\n        if (lineNumber < firstInvalidLineNumber) {\n            return true;\n        }\n        if (lineNumber === firstInvalidLineNumber\n            && this._textModel.getLineLength(lineNumber) < 2048 /* Constants.CHEAP_TOKENIZATION_LENGTH_LIMIT */) {\n            return true;\n        }\n        return false;\n    }\n    /**\n     * The result is not cached.\n     */\n    tokenizeHeuristically(builder, startLineNumber, endLineNumber) {\n        if (endLineNumber <= this.store.getFirstInvalidEndStateLineNumberOrMax()) {\n            // nothing to do\n            return { heuristicTokens: false };\n        }\n        if (startLineNumber <= this.store.getFirstInvalidEndStateLineNumberOrMax()) {\n            // tokenization has reached the viewport start...\n            this.updateTokensUntilLine(builder, endLineNumber);\n            return { heuristicTokens: false };\n        }\n        let state = this.guessStartState(startLineNumber);\n        const languageId = this._textModel.getLanguageId();\n        for (let lineNumber = startLineNumber; lineNumber <= endLineNumber; lineNumber++) {\n            const text = this._textModel.getLineContent(lineNumber);\n            const r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, text, true, state);\n            builder.add(lineNumber, r.tokens);\n            state = r.endState;\n        }\n        return { heuristicTokens: true };\n    }\n    guessStartState(lineNumber) {\n        let nonWhitespaceColumn = this._textModel.getLineFirstNonWhitespaceColumn(lineNumber);\n        const likelyRelevantLines = [];\n        let initialState = null;\n        for (let i = lineNumber - 1; nonWhitespaceColumn > 1 && i >= 1; i--) {\n            const newNonWhitespaceIndex = this._textModel.getLineFirstNonWhitespaceColumn(i);\n            // Ignore lines full of whitespace\n            if (newNonWhitespaceIndex === 0) {\n                continue;\n            }\n            if (newNonWhitespaceIndex < nonWhitespaceColumn) {\n                likelyRelevantLines.push(this._textModel.getLineContent(i));\n                nonWhitespaceColumn = newNonWhitespaceIndex;\n                initialState = this.getStartState(i);\n                if (initialState) {\n                    break;\n                }\n            }\n        }\n        if (!initialState) {\n            initialState = this.tokenizationSupport.getInitialState();\n        }\n        likelyRelevantLines.reverse();\n        const languageId = this._textModel.getLanguageId();\n        let state = initialState;\n        for (const line of likelyRelevantLines) {\n            const r = safeTokenize(this._languageIdCodec, languageId, this.tokenizationSupport, line, false, state);\n            state = r.endState;\n        }\n        return state;\n    }\n}\n/**\n * **Invariant:**\n * If the text model is retokenized from line 1 to {@link getFirstInvalidEndStateLineNumber}() - 1,\n * then the recomputed end state for line l will be equal to {@link getEndState}(l).\n */\nexport class TrackingTokenizationStateStore {\n    constructor(lineCount) {\n        this.lineCount = lineCount;\n        this._tokenizationStateStore = new TokenizationStateStore();\n        this._invalidEndStatesLineNumbers = new RangePriorityQueueImpl();\n        this._invalidEndStatesLineNumbers.addRange(new OffsetRange(1, lineCount + 1));\n    }\n    getEndState(lineNumber) {\n        return this._tokenizationStateStore.getEndState(lineNumber);\n    }\n    /**\n     * @returns if the end state has changed.\n     */\n    setEndState(lineNumber, state) {\n        if (!state) {\n            throw new BugIndicatingError('Cannot set null/undefined state');\n        }\n        this._invalidEndStatesLineNumbers.delete(lineNumber);\n        const r = this._tokenizationStateStore.setEndState(lineNumber, state);\n        if (r && lineNumber < this.lineCount) {\n            // because the state changed, we cannot trust the next state anymore and have to invalidate it.\n            this._invalidEndStatesLineNumbers.addRange(new OffsetRange(lineNumber + 1, lineNumber + 2));\n        }\n        return r;\n    }\n    acceptChange(range, newLineCount) {\n        this.lineCount += newLineCount - range.length;\n        this._tokenizationStateStore.acceptChange(range, newLineCount);\n        this._invalidEndStatesLineNumbers.addRangeAndResize(new OffsetRange(range.startLineNumber, range.endLineNumberExclusive), newLineCount);\n    }\n    acceptChanges(changes) {\n        for (const c of changes) {\n            const [eolCount] = countEOL(c.text);\n            this.acceptChange(new LineRange(c.range.startLineNumber, c.range.endLineNumber + 1), eolCount + 1);\n        }\n    }\n    invalidateEndStateRange(range) {\n        this._invalidEndStatesLineNumbers.addRange(new OffsetRange(range.startLineNumber, range.endLineNumberExclusive));\n    }\n    getFirstInvalidEndStateLineNumber() { return this._invalidEndStatesLineNumbers.min; }\n    getFirstInvalidEndStateLineNumberOrMax() {\n        return this.getFirstInvalidEndStateLineNumber() || Number.MAX_SAFE_INTEGER;\n    }\n    allStatesValid() { return this._invalidEndStatesLineNumbers.min === null; }\n    getStartState(lineNumber, initialState) {\n        if (lineNumber === 1) {\n            return initialState;\n        }\n        return this.getEndState(lineNumber - 1);\n    }\n    getFirstInvalidLine(initialState) {\n        const lineNumber = this.getFirstInvalidEndStateLineNumber();\n        if (lineNumber === null) {\n            return null;\n        }\n        const startState = this.getStartState(lineNumber, initialState);\n        if (!startState) {\n            throw new BugIndicatingError('Start state must be defined');\n        }\n        return { lineNumber, startState };\n    }\n}\nexport class TokenizationStateStore {\n    constructor() {\n        this._lineEndStates = new FixedArray(null);\n    }\n    getEndState(lineNumber) {\n        return this._lineEndStates.get(lineNumber);\n    }\n    setEndState(lineNumber, state) {\n        const oldState = this._lineEndStates.get(lineNumber);\n        if (oldState && oldState.equals(state)) {\n            return false;\n        }\n        this._lineEndStates.set(lineNumber, state);\n        return true;\n    }\n    acceptChange(range, newLineCount) {\n        let length = range.length;\n        if (newLineCount > 0 && length > 0) {\n            // Keep the last state, even though it is unrelated.\n            // But if the new state happens to agree with this last state, then we know we can stop tokenizing.\n            length--;\n            newLineCount--;\n        }\n        this._lineEndStates.replace(range.startLineNumber, length, newLineCount);\n    }\n}\nexport class RangePriorityQueueImpl {\n    constructor() {\n        this._ranges = [];\n    }\n    get min() {\n        if (this._ranges.length === 0) {\n            return null;\n        }\n        return this._ranges[0].start;\n    }\n    delete(value) {\n        const idx = this._ranges.findIndex(r => r.contains(value));\n        if (idx !== -1) {\n            const range = this._ranges[idx];\n            if (range.start === value) {\n                if (range.endExclusive === value + 1) {\n                    this._ranges.splice(idx, 1);\n                }\n                else {\n                    this._ranges[idx] = new OffsetRange(value + 1, range.endExclusive);\n                }\n            }\n            else {\n                if (range.endExclusive === value + 1) {\n                    this._ranges[idx] = new OffsetRange(range.start, value);\n                }\n                else {\n                    this._ranges.splice(idx, 1, new OffsetRange(range.start, value), new OffsetRange(value + 1, range.endExclusive));\n                }\n            }\n        }\n    }\n    addRange(range) {\n        OffsetRange.addRange(range, this._ranges);\n    }\n    addRangeAndResize(range, newLength) {\n        let idxFirstMightBeIntersecting = 0;\n        while (!(idxFirstMightBeIntersecting >= this._ranges.length || range.start <= this._ranges[idxFirstMightBeIntersecting].endExclusive)) {\n            idxFirstMightBeIntersecting++;\n        }\n        let idxFirstIsAfter = idxFirstMightBeIntersecting;\n        while (!(idxFirstIsAfter >= this._ranges.length || range.endExclusive < this._ranges[idxFirstIsAfter].start)) {\n            idxFirstIsAfter++;\n        }\n        const delta = newLength - range.length;\n        for (let i = idxFirstIsAfter; i < this._ranges.length; i++) {\n            this._ranges[i] = this._ranges[i].delta(delta);\n        }\n        if (idxFirstMightBeIntersecting === idxFirstIsAfter) {\n            const newRange = new OffsetRange(range.start, range.start + newLength);\n            if (!newRange.isEmpty) {\n                this._ranges.splice(idxFirstMightBeIntersecting, 0, newRange);\n            }\n        }\n        else {\n            const start = Math.min(range.start, this._ranges[idxFirstMightBeIntersecting].start);\n            const endEx = Math.max(range.endExclusive, this._ranges[idxFirstIsAfter - 1].endExclusive);\n            const newRange = new OffsetRange(start, endEx + delta);\n            if (!newRange.isEmpty) {\n                this._ranges.splice(idxFirstMightBeIntersecting, idxFirstIsAfter - idxFirstMightBeIntersecting, newRange);\n            }\n            else {\n                this._ranges.splice(idxFirstMightBeIntersecting, idxFirstIsAfter - idxFirstMightBeIntersecting);\n            }\n        }\n    }\n    toString() {\n        return this._ranges.map(r => r.toString()).join(' + ');\n    }\n}\nfunction safeTokenize(languageIdCodec, languageId, tokenizationSupport, text, hasEOL, state) {\n    let r = null;\n    if (tokenizationSupport) {\n        try {\n            r = tokenizationSupport.tokenizeEncoded(text, hasEOL, state.clone());\n        }\n        catch (e) {\n            onUnexpectedError(e);\n        }\n    }\n    if (!r) {\n        r = nullTokenizeEncoded(languageIdCodec.encodeLanguageId(languageId), state);\n    }\n    LineTokens.convertToEndOffset(r.tokens, text.length);\n    return r;\n}\nexport class DefaultBackgroundTokenizer {\n    constructor(_tokenizerWithStateStore, _backgroundTokenStore) {\n        this._tokenizerWithStateStore = _tokenizerWithStateStore;\n        this._backgroundTokenStore = _backgroundTokenStore;\n        this._isDisposed = false;\n        this._isScheduled = false;\n    }\n    dispose() {\n        this._isDisposed = true;\n    }\n    handleChanges() {\n        this._beginBackgroundTokenization();\n    }\n    _beginBackgroundTokenization() {\n        if (this._isScheduled || !this._tokenizerWithStateStore._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n            return;\n        }\n        this._isScheduled = true;\n        runWhenGlobalIdle((deadline) => {\n            this._isScheduled = false;\n            this._backgroundTokenizeWithDeadline(deadline);\n        });\n    }\n    /**\n     * Tokenize until the deadline occurs, but try to yield every 1-2ms.\n     */\n    _backgroundTokenizeWithDeadline(deadline) {\n        // Read the time remaining from the `deadline` immediately because it is unclear\n        // if the `deadline` object will be valid after execution leaves this function.\n        const endTime = Date.now() + deadline.timeRemaining();\n        const execute = () => {\n            if (this._isDisposed || !this._tokenizerWithStateStore._textModel.isAttachedToEditor() || !this._hasLinesToTokenize()) {\n                // disposed in the meantime or detached or finished\n                return;\n            }\n            this._backgroundTokenizeForAtLeast1ms();\n            if (Date.now() < endTime) {\n                // There is still time before reaching the deadline, so yield to the browser and then\n                // continue execution\n                setTimeout0(execute);\n            }\n            else {\n                // The deadline has been reached, so schedule a new idle callback if necessary\n                this._beginBackgroundTokenization();\n            }\n        };\n        execute();\n    }\n    /**\n     * Tokenize for at least 1ms.\n     */\n    _backgroundTokenizeForAtLeast1ms() {\n        const lineCount = this._tokenizerWithStateStore._textModel.getLineCount();\n        const builder = new ContiguousMultilineTokensBuilder();\n        const sw = StopWatch.create(false);\n        do {\n            if (sw.elapsed() > 1) {\n                // the comparison is intentionally > 1 and not >= 1 to ensure that\n                // a full millisecond has elapsed, given how microseconds are rounded\n                // to milliseconds\n                break;\n            }\n            const tokenizedLineNumber = this._tokenizeOneInvalidLine(builder);\n            if (tokenizedLineNumber >= lineCount) {\n                break;\n            }\n        } while (this._hasLinesToTokenize());\n        this._backgroundTokenStore.setTokens(builder.finalize());\n        this.checkFinished();\n    }\n    _hasLinesToTokenize() {\n        if (!this._tokenizerWithStateStore) {\n            return false;\n        }\n        return !this._tokenizerWithStateStore.store.allStatesValid();\n    }\n    _tokenizeOneInvalidLine(builder) {\n        var _a;\n        const firstInvalidLine = (_a = this._tokenizerWithStateStore) === null || _a === void 0 ? void 0 : _a.getFirstInvalidLine();\n        if (!firstInvalidLine) {\n            return this._tokenizerWithStateStore._textModel.getLineCount() + 1;\n        }\n        this._tokenizerWithStateStore.updateTokensUntilLine(builder, firstInvalidLine.lineNumber);\n        return firstInvalidLine.lineNumber;\n    }\n    checkFinished() {\n        if (this._isDisposed) {\n            return;\n        }\n        if (this._tokenizerWithStateStore.store.allStatesValid()) {\n            this._backgroundTokenStore.backgroundTokenizationFinished();\n        }\n    }\n    requestTokens(startLineNumber, endLineNumberExclusive) {\n        this._tokenizerWithStateStore.store.invalidateEndStateRange(new LineRange(startLineNumber, endLineNumberExclusive));\n    }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA,SAASA,iBAAiB,QAAQ,+BAA+B;AACjE,SAASC,kBAAkB,EAAEC,iBAAiB,QAAQ,gCAAgC;AACtF,SAASC,WAAW,QAAQ,kCAAkC;AAC9D,SAASC,SAAS,QAAQ,mCAAmC;AAC7D,SAASC,QAAQ,QAAQ,uBAAuB;AAChD,SAASC,SAAS,QAAQ,sBAAsB;AAChD,SAASC,WAAW,QAAQ,wBAAwB;AACpD,SAASC,mBAAmB,QAAQ,8BAA8B;AAClE,SAASC,UAAU,QAAQ,iBAAiB;AAC5C,SAASC,gCAAgC,QAAQ,+CAA+C;AAChG,SAASC,UAAU,QAAQ,yBAAyB;AACpD,WAAaC,uBAAuB;EAChC,SAAAA,wBAAYC,SAAS,EAAEC,mBAAmB,EAAE;IAAAC,eAAA,OAAAH,uBAAA;IACxC,IAAI,CAACE,mBAAmB,GAAGA,mBAAmB;IAC9C,IAAI,CAACE,YAAY,GAAG,IAAI,CAACF,mBAAmB,CAACG,eAAe,CAAC,CAAC;IAC9D,IAAI,CAACC,KAAK,GAAG,IAAIC,8BAA8B,CAACN,SAAS,CAAC;EAC9D;EAAC,OAAAO,YAAA,CAAAR,uBAAA;IAAAS,GAAA;IAAAC,KAAA,EACD,SAAAC,cAAcC,UAAU,EAAE;MACtB,OAAO,IAAI,CAACN,KAAK,CAACK,aAAa,CAACC,UAAU,EAAE,IAAI,CAACR,YAAY,CAAC;IAClE;EAAC;IAAAK,GAAA;IAAAC,KAAA,EACD,SAAAG,oBAAA,EAAsB;MAClB,OAAO,IAAI,CAACP,KAAK,CAACO,mBAAmB,CAAC,IAAI,CAACT,YAAY,CAAC;IAC5D;EAAC;AAAA;AAEL,WAAaU,mCAAmC,0BAAAC,qBAAA;EAC5C,SAAAD,oCAAYb,SAAS,EAAEC,mBAAmB,EAAEc,UAAU,EAAEC,gBAAgB,EAAE;IAAA,IAAAC,KAAA;IAAAf,eAAA,OAAAW,mCAAA;IACtEI,KAAA,GAAAC,UAAA,OAAAL,mCAAA,GAAMb,SAAS,EAAEC,mBAAmB;IACpCgB,KAAA,CAAKF,UAAU,GAAGA,UAAU;IAC5BE,KAAA,CAAKD,gBAAgB,GAAGA,gBAAgB;IAAC,OAAAC,KAAA;EAC7C;EAACE,SAAA,CAAAN,mCAAA,EAAAC,qBAAA;EAAA,OAAAP,YAAA,CAAAM,mCAAA;IAAAL,GAAA;IAAAC,KAAA,EACD,SAAAW,sBAAsBC,OAAO,EAAEV,UAAU,EAAE;MACvC,IAAMW,UAAU,GAAG,IAAI,CAACP,UAAU,CAACQ,aAAa,CAAC,CAAC;MAClD,OAAO,IAAI,EAAE;QACT,IAAMC,cAAc,GAAG,IAAI,CAACZ,mBAAmB,CAAC,CAAC;QACjD,IAAI,CAACY,cAAc,IAAIA,cAAc,CAACb,UAAU,GAAGA,UAAU,EAAE;UAC3D;QACJ;QACA,IAAMc,IAAI,GAAG,IAAI,CAACV,UAAU,CAACW,cAAc,CAACF,cAAc,CAACb,UAAU,CAAC;QACtE,IAAMgB,CAAC,GAAGC,YAAY,CAAC,IAAI,CAACZ,gBAAgB,EAAEM,UAAU,EAAE,IAAI,CAACrB,mBAAmB,EAAEwB,IAAI,EAAE,IAAI,EAAED,cAAc,CAACK,UAAU,CAAC;QAC1HR,OAAO,CAACS,GAAG,CAACN,cAAc,CAACb,UAAU,EAAEgB,CAAC,CAACI,MAAM,CAAC;QAChD,IAAI,CAAC1B,KAAK,CAAC2B,WAAW,CAACR,cAAc,CAACb,UAAU,EAAEgB,CAAC,CAACM,QAAQ,CAAC;MACjE;IACJ;IACA;EAAA;IAAAzB,GAAA;IAAAC,KAAA,EACA,SAAAyB,iCAAiCC,QAAQ,EAAEC,SAAS,EAAE;MAClD;MACA,IAAMC,cAAc,GAAG,IAAI,CAAC3B,aAAa,CAACyB,QAAQ,CAACxB,UAAU,CAAC;MAC9D,IAAI,CAAC0B,cAAc,EAAE;QACjB,OAAO,CAAC,CAAC;MACb;MACA,IAAMf,UAAU,GAAG,IAAI,CAACP,UAAU,CAACQ,aAAa,CAAC,CAAC;MAClD,IAAMe,WAAW,GAAG,IAAI,CAACvB,UAAU,CAACW,cAAc,CAACS,QAAQ,CAACxB,UAAU,CAAC;MACvE;MACA,IAAMc,IAAI,GAAIa,WAAW,CAACC,SAAS,CAAC,CAAC,EAAEJ,QAAQ,CAACK,MAAM,GAAG,CAAC,CAAC,GACrDJ,SAAS,GACTE,WAAW,CAACC,SAAS,CAACJ,QAAQ,CAACK,MAAM,GAAG,CAAC,CAAE;MACjD,IAAMb,CAAC,GAAGC,YAAY,CAAC,IAAI,CAACZ,gBAAgB,EAAEM,UAAU,EAAE,IAAI,CAACrB,mBAAmB,EAAEwB,IAAI,EAAE,IAAI,EAAEY,cAAc,CAAC;MAC/G,IAAMI,UAAU,GAAG,IAAI3C,UAAU,CAAC6B,CAAC,CAACI,MAAM,EAAEN,IAAI,EAAE,IAAI,CAACT,gBAAgB,CAAC;MACxE,IAAIyB,UAAU,CAACC,QAAQ,CAAC,CAAC,KAAK,CAAC,EAAE;QAC7B,OAAO,CAAC,CAAC;MACb;MACA,IAAMC,UAAU,GAAGF,UAAU,CAACG,sBAAsB,CAACT,QAAQ,CAACK,MAAM,GAAG,CAAC,CAAC;MACzE,OAAOC,UAAU,CAACI,oBAAoB,CAACF,UAAU,CAAC;IACtD;IACA;EAAA;IAAAnC,GAAA;IAAAC,KAAA,EACA,SAAAqC,qBAAqBX,QAAQ,EAAEY,MAAM,EAAEC,OAAO,EAAE;MAC5C,IAAMrC,UAAU,GAAGwB,QAAQ,CAACxB,UAAU;MACtC,IAAM6B,MAAM,GAAGL,QAAQ,CAACK,MAAM;MAC9B,IAAMH,cAAc,GAAG,IAAI,CAAC3B,aAAa,CAACC,UAAU,CAAC;MACrD,IAAI,CAAC0B,cAAc,EAAE;QACjB,OAAO,IAAI;MACf;MACA,IAAMY,cAAc,GAAG,IAAI,CAAClC,UAAU,CAACW,cAAc,CAACf,UAAU,CAAC;MACjE,IAAMuC,cAAc,GAAGD,cAAc,CAACV,SAAS,CAAC,CAAC,EAAEC,MAAM,GAAG,CAAC,CAAC,GACxDQ,OAAO,GAAGC,cAAc,CAACV,SAAS,CAACC,MAAM,GAAG,CAAC,GAAGO,MAAM,CAAC;MAC7D,IAAMzB,UAAU,GAAG,IAAI,CAACP,UAAU,CAACoC,uBAAuB,CAACxC,UAAU,EAAE,CAAC,CAAC;MACzE,IAAMyC,MAAM,GAAGxB,YAAY,CAAC,IAAI,CAACZ,gBAAgB,EAAEM,UAAU,EAAE,IAAI,CAACrB,mBAAmB,EAAEiD,cAAc,EAAE,IAAI,EAAEb,cAAc,CAAC;MAC9H,IAAMI,UAAU,GAAG,IAAI3C,UAAU,CAACsD,MAAM,CAACrB,MAAM,EAAEmB,cAAc,EAAE,IAAI,CAAClC,gBAAgB,CAAC;MACvF,OAAOyB,UAAU;IACrB;EAAC;IAAAjC,GAAA;IAAAC,KAAA,EACD,SAAA4C,yBAAyB1C,UAAU,EAAE;MACjC,IAAM2C,sBAAsB,GAAG,IAAI,CAACjD,KAAK,CAACkD,sCAAsC,CAAC,CAAC;MAClF,OAAQ5C,UAAU,GAAG2C,sBAAsB;IAC/C;EAAC;IAAA9C,GAAA;IAAAC,KAAA,EACD,SAAA+C,kBAAkB7C,UAAU,EAAE;MAC1B,IAAM2C,sBAAsB,GAAG,IAAI,CAACjD,KAAK,CAACkD,sCAAsC,CAAC,CAAC;MAClF,IAAI5C,UAAU,GAAG2C,sBAAsB,EAAE;QACrC,OAAO,IAAI;MACf;MACA,IAAI3C,UAAU,KAAK2C,sBAAsB,IAClC,IAAI,CAACvC,UAAU,CAAC0C,aAAa,CAAC9C,UAAU,CAAC,GAAG,IAAI,CAAC,iDAAiD;QACrG,OAAO,IAAI;MACf;MACA,OAAO,KAAK;IAChB;IACA;AACJ;AACA;EAFI;IAAAH,GAAA;IAAAC,KAAA,EAGA,SAAAiD,sBAAsBrC,OAAO,EAAEsC,eAAe,EAAEC,aAAa,EAAE;MAC3D,IAAIA,aAAa,IAAI,IAAI,CAACvD,KAAK,CAACkD,sCAAsC,CAAC,CAAC,EAAE;QACtE;QACA,OAAO;UAAEM,eAAe,EAAE;QAAM,CAAC;MACrC;MACA,IAAIF,eAAe,IAAI,IAAI,CAACtD,KAAK,CAACkD,sCAAsC,CAAC,CAAC,EAAE;QACxE;QACA,IAAI,CAACnC,qBAAqB,CAACC,OAAO,EAAEuC,aAAa,CAAC;QAClD,OAAO;UAAEC,eAAe,EAAE;QAAM,CAAC;MACrC;MACA,IAAIC,KAAK,GAAG,IAAI,CAACC,eAAe,CAACJ,eAAe,CAAC;MACjD,IAAMrC,UAAU,GAAG,IAAI,CAACP,UAAU,CAACQ,aAAa,CAAC,CAAC;MAClD,KAAK,IAAIZ,UAAU,GAAGgD,eAAe,EAAEhD,UAAU,IAAIiD,aAAa,EAAEjD,UAAU,EAAE,EAAE;QAC9E,IAAMc,IAAI,GAAG,IAAI,CAACV,UAAU,CAACW,cAAc,CAACf,UAAU,CAAC;QACvD,IAAMgB,CAAC,GAAGC,YAAY,CAAC,IAAI,CAACZ,gBAAgB,EAAEM,UAAU,EAAE,IAAI,CAACrB,mBAAmB,EAAEwB,IAAI,EAAE,IAAI,EAAEqC,KAAK,CAAC;QACtGzC,OAAO,CAACS,GAAG,CAACnB,UAAU,EAAEgB,CAAC,CAACI,MAAM,CAAC;QACjC+B,KAAK,GAAGnC,CAAC,CAACM,QAAQ;MACtB;MACA,OAAO;QAAE4B,eAAe,EAAE;MAAK,CAAC;IACpC;EAAC;IAAArD,GAAA;IAAAC,KAAA,EACD,SAAAsD,gBAAgBpD,UAAU,EAAE;MACxB,IAAIqD,mBAAmB,GAAG,IAAI,CAACjD,UAAU,CAACkD,+BAA+B,CAACtD,UAAU,CAAC;MACrF,IAAMuD,mBAAmB,GAAG,EAAE;MAC9B,IAAI/D,YAAY,GAAG,IAAI;MACvB,KAAK,IAAIgE,CAAC,GAAGxD,UAAU,GAAG,CAAC,EAAEqD,mBAAmB,GAAG,CAAC,IAAIG,CAAC,IAAI,CAAC,EAAEA,CAAC,EAAE,EAAE;QACjE,IAAMC,qBAAqB,GAAG,IAAI,CAACrD,UAAU,CAACkD,+BAA+B,CAACE,CAAC,CAAC;QAChF;QACA,IAAIC,qBAAqB,KAAK,CAAC,EAAE;UAC7B;QACJ;QACA,IAAIA,qBAAqB,GAAGJ,mBAAmB,EAAE;UAC7CE,mBAAmB,CAACG,IAAI,CAAC,IAAI,CAACtD,UAAU,CAACW,cAAc,CAACyC,CAAC,CAAC,CAAC;UAC3DH,mBAAmB,GAAGI,qBAAqB;UAC3CjE,YAAY,GAAG,IAAI,CAACO,aAAa,CAACyD,CAAC,CAAC;UACpC,IAAIhE,YAAY,EAAE;YACd;UACJ;QACJ;MACJ;MACA,IAAI,CAACA,YAAY,EAAE;QACfA,YAAY,GAAG,IAAI,CAACF,mBAAmB,CAACG,eAAe,CAAC,CAAC;MAC7D;MACA8D,mBAAmB,CAACI,OAAO,CAAC,CAAC;MAC7B,IAAMhD,UAAU,GAAG,IAAI,CAACP,UAAU,CAACQ,aAAa,CAAC,CAAC;MAClD,IAAIuC,KAAK,GAAG3D,YAAY;MACxB,SAAAoE,EAAA,MAAAC,oBAAA,GAAmBN,mBAAmB,EAAAK,EAAA,GAAAC,oBAAA,CAAAzB,MAAA,EAAAwB,EAAA,IAAE;QAAnC,IAAME,IAAI,GAAAD,oBAAA,CAAAD,EAAA;QACX,IAAM5C,CAAC,GAAGC,YAAY,CAAC,IAAI,CAACZ,gBAAgB,EAAEM,UAAU,EAAE,IAAI,CAACrB,mBAAmB,EAAEwE,IAAI,EAAE,KAAK,EAAEX,KAAK,CAAC;QACvGA,KAAK,GAAGnC,CAAC,CAACM,QAAQ;MACtB;MACA,OAAO6B,KAAK;IAChB;EAAC;AAAA,EA5HoD/D,uBAAuB;AA8HhF;AACA;AACA;AACA;AACA;AACA,WAAaO,8BAA8B;EACvC,SAAAA,+BAAYN,SAAS,EAAE;IAAAE,eAAA,OAAAI,8BAAA;IACnB,IAAI,CAACN,SAAS,GAAGA,SAAS;IAC1B,IAAI,CAAC0E,uBAAuB,GAAG,IAAIC,sBAAsB,CAAC,CAAC;IAC3D,IAAI,CAACC,4BAA4B,GAAG,IAAIC,sBAAsB,CAAC,CAAC;IAChE,IAAI,CAACD,4BAA4B,CAACE,QAAQ,CAAC,IAAIpF,WAAW,CAAC,CAAC,EAAEM,SAAS,GAAG,CAAC,CAAC,CAAC;EACjF;EAAC,OAAAO,YAAA,CAAAD,8BAAA;IAAAE,GAAA;IAAAC,KAAA,EACD,SAAAsE,YAAYpE,UAAU,EAAE;MACpB,OAAO,IAAI,CAAC+D,uBAAuB,CAACK,WAAW,CAACpE,UAAU,CAAC;IAC/D;IACA;AACJ;AACA;EAFI;IAAAH,GAAA;IAAAC,KAAA,EAGA,SAAAuB,YAAYrB,UAAU,EAAEmD,KAAK,EAAE;MAC3B,IAAI,CAACA,KAAK,EAAE;QACR,MAAM,IAAI1E,kBAAkB,CAAC,iCAAiC,CAAC;MACnE;MACA,IAAI,CAACwF,4BAA4B,UAAO,CAACjE,UAAU,CAAC;MACpD,IAAMgB,CAAC,GAAG,IAAI,CAAC+C,uBAAuB,CAAC1C,WAAW,CAACrB,UAAU,EAAEmD,KAAK,CAAC;MACrE,IAAInC,CAAC,IAAIhB,UAAU,GAAG,IAAI,CAACX,SAAS,EAAE;QAClC;QACA,IAAI,CAAC4E,4BAA4B,CAACE,QAAQ,CAAC,IAAIpF,WAAW,CAACiB,UAAU,GAAG,CAAC,EAAEA,UAAU,GAAG,CAAC,CAAC,CAAC;MAC/F;MACA,OAAOgB,CAAC;IACZ;EAAC;IAAAnB,GAAA;IAAAC,KAAA,EACD,SAAAuE,aAAaC,KAAK,EAAEC,YAAY,EAAE;MAC9B,IAAI,CAAClF,SAAS,IAAIkF,YAAY,GAAGD,KAAK,CAAClC,MAAM;MAC7C,IAAI,CAAC2B,uBAAuB,CAACM,YAAY,CAACC,KAAK,EAAEC,YAAY,CAAC;MAC9D,IAAI,CAACN,4BAA4B,CAACO,iBAAiB,CAAC,IAAIzF,WAAW,CAACuF,KAAK,CAACtB,eAAe,EAAEsB,KAAK,CAACG,sBAAsB,CAAC,EAAEF,YAAY,CAAC;IAC3I;EAAC;IAAA1E,GAAA;IAAAC,KAAA,EACD,SAAA4E,cAAcC,OAAO,EAAE;MAAA,IAAAC,SAAA,GAAAC,0BAAA,CACHF,OAAO;QAAAG,KAAA;MAAA;QAAvB,KAAAF,SAAA,CAAAG,CAAA,MAAAD,KAAA,GAAAF,SAAA,CAAAI,CAAA,IAAAC,IAAA,GAAyB;UAAA,IAAdC,CAAC,GAAAJ,KAAA,CAAAhF,KAAA;UACR,IAAAqF,SAAA,GAAmBtG,QAAQ,CAACqG,CAAC,CAACpE,IAAI,CAAC;YAAAsE,UAAA,GAAAC,cAAA,CAAAF,SAAA;YAA5BG,QAAQ,GAAAF,UAAA;UACf,IAAI,CAACf,YAAY,CAAC,IAAIvF,SAAS,CAACoG,CAAC,CAACZ,KAAK,CAACtB,eAAe,EAAEkC,CAAC,CAACZ,KAAK,CAACrB,aAAa,GAAG,CAAC,CAAC,EAAEqC,QAAQ,GAAG,CAAC,CAAC;QACtG;MAAC,SAAAC,GAAA;QAAAX,SAAA,CAAAY,CAAA,CAAAD,GAAA;MAAA;QAAAX,SAAA,CAAAa,CAAA;MAAA;IACL;EAAC;IAAA5F,GAAA;IAAAC,KAAA,EACD,SAAA4F,wBAAwBpB,KAAK,EAAE;MAC3B,IAAI,CAACL,4BAA4B,CAACE,QAAQ,CAAC,IAAIpF,WAAW,CAACuF,KAAK,CAACtB,eAAe,EAAEsB,KAAK,CAACG,sBAAsB,CAAC,CAAC;IACpH;EAAC;IAAA5E,GAAA;IAAAC,KAAA,EACD,SAAA6F,kCAAA,EAAoC;MAAE,OAAO,IAAI,CAAC1B,4BAA4B,CAAC2B,GAAG;IAAE;EAAC;IAAA/F,GAAA;IAAAC,KAAA,EACrF,SAAA8C,uCAAA,EAAyC;MACrC,OAAO,IAAI,CAAC+C,iCAAiC,CAAC,CAAC,IAAIE,MAAM,CAACC,gBAAgB;IAC9E;EAAC;IAAAjG,GAAA;IAAAC,KAAA,EACD,SAAAiG,eAAA,EAAiB;MAAE,OAAO,IAAI,CAAC9B,4BAA4B,CAAC2B,GAAG,KAAK,IAAI;IAAE;EAAC;IAAA/F,GAAA;IAAAC,KAAA,EAC3E,SAAAC,cAAcC,UAAU,EAAER,YAAY,EAAE;MACpC,IAAIQ,UAAU,KAAK,CAAC,EAAE;QAClB,OAAOR,YAAY;MACvB;MACA,OAAO,IAAI,CAAC4E,WAAW,CAACpE,UAAU,GAAG,CAAC,CAAC;IAC3C;EAAC;IAAAH,GAAA;IAAAC,KAAA,EACD,SAAAG,oBAAoBT,YAAY,EAAE;MAC9B,IAAMQ,UAAU,GAAG,IAAI,CAAC2F,iCAAiC,CAAC,CAAC;MAC3D,IAAI3F,UAAU,KAAK,IAAI,EAAE;QACrB,OAAO,IAAI;MACf;MACA,IAAMkB,UAAU,GAAG,IAAI,CAACnB,aAAa,CAACC,UAAU,EAAER,YAAY,CAAC;MAC/D,IAAI,CAAC0B,UAAU,EAAE;QACb,MAAM,IAAIzC,kBAAkB,CAAC,6BAA6B,CAAC;MAC/D;MACA,OAAO;QAAEuB,UAAU,EAAVA,UAAU;QAAEkB,UAAU,EAAVA;MAAW,CAAC;IACrC;EAAC;AAAA;AAEL,WAAa8C,sBAAsB;EAC/B,SAAAA,uBAAA,EAAc;IAAAzE,eAAA,OAAAyE,sBAAA;IACV,IAAI,CAACgC,cAAc,GAAG,IAAI/G,UAAU,CAAC,IAAI,CAAC;EAC9C;EAAC,OAAAW,YAAA,CAAAoE,sBAAA;IAAAnE,GAAA;IAAAC,KAAA,EACD,SAAAsE,YAAYpE,UAAU,EAAE;MACpB,OAAO,IAAI,CAACgG,cAAc,CAACC,GAAG,CAACjG,UAAU,CAAC;IAC9C;EAAC;IAAAH,GAAA;IAAAC,KAAA,EACD,SAAAuB,YAAYrB,UAAU,EAAEmD,KAAK,EAAE;MAC3B,IAAM+C,QAAQ,GAAG,IAAI,CAACF,cAAc,CAACC,GAAG,CAACjG,UAAU,CAAC;MACpD,IAAIkG,QAAQ,IAAIA,QAAQ,CAACC,MAAM,CAAChD,KAAK,CAAC,EAAE;QACpC,OAAO,KAAK;MAChB;MACA,IAAI,CAAC6C,cAAc,CAACI,GAAG,CAACpG,UAAU,EAAEmD,KAAK,CAAC;MAC1C,OAAO,IAAI;IACf;EAAC;IAAAtD,GAAA;IAAAC,KAAA,EACD,SAAAuE,aAAaC,KAAK,EAAEC,YAAY,EAAE;MAC9B,IAAInC,MAAM,GAAGkC,KAAK,CAAClC,MAAM;MACzB,IAAImC,YAAY,GAAG,CAAC,IAAInC,MAAM,GAAG,CAAC,EAAE;QAChC;QACA;QACAA,MAAM,EAAE;QACRmC,YAAY,EAAE;MAClB;MACA,IAAI,CAACyB,cAAc,CAACK,OAAO,CAAC/B,KAAK,CAACtB,eAAe,EAAEZ,MAAM,EAAEmC,YAAY,CAAC;IAC5E;EAAC;AAAA;AAEL,WAAaL,sBAAsB;EAC/B,SAAAA,uBAAA,EAAc;IAAA3E,eAAA,OAAA2E,sBAAA;IACV,IAAI,CAACoC,OAAO,GAAG,EAAE;EACrB;EAAC,OAAA1G,YAAA,CAAAsE,sBAAA;IAAArE,GAAA;IAAAoG,GAAA,EACD,SAAAA,IAAA,EAAU;MACN,IAAI,IAAI,CAACK,OAAO,CAAClE,MAAM,KAAK,CAAC,EAAE;QAC3B,OAAO,IAAI;MACf;MACA,OAAO,IAAI,CAACkE,OAAO,CAAC,CAAC,CAAC,CAACC,KAAK;IAChC;EAAC;IAAA1G,GAAA;IAAAC,KAAA,EACD,SAAA0G,QAAO1G,KAAK,EAAE;MACV,IAAM2G,GAAG,GAAG,IAAI,CAACH,OAAO,CAACI,SAAS,CAAC,UAAA1F,CAAC;QAAA,OAAIA,CAAC,CAAC2F,QAAQ,CAAC7G,KAAK,CAAC;MAAA,EAAC;MAC1D,IAAI2G,GAAG,KAAK,CAAC,CAAC,EAAE;QACZ,IAAMnC,KAAK,GAAG,IAAI,CAACgC,OAAO,CAACG,GAAG,CAAC;QAC/B,IAAInC,KAAK,CAACiC,KAAK,KAAKzG,KAAK,EAAE;UACvB,IAAIwE,KAAK,CAACsC,YAAY,KAAK9G,KAAK,GAAG,CAAC,EAAE;YAClC,IAAI,CAACwG,OAAO,CAACO,MAAM,CAACJ,GAAG,EAAE,CAAC,CAAC;UAC/B,CAAC,MACI;YACD,IAAI,CAACH,OAAO,CAACG,GAAG,CAAC,GAAG,IAAI1H,WAAW,CAACe,KAAK,GAAG,CAAC,EAAEwE,KAAK,CAACsC,YAAY,CAAC;UACtE;QACJ,CAAC,MACI;UACD,IAAItC,KAAK,CAACsC,YAAY,KAAK9G,KAAK,GAAG,CAAC,EAAE;YAClC,IAAI,CAACwG,OAAO,CAACG,GAAG,CAAC,GAAG,IAAI1H,WAAW,CAACuF,KAAK,CAACiC,KAAK,EAAEzG,KAAK,CAAC;UAC3D,CAAC,MACI;YACD,IAAI,CAACwG,OAAO,CAACO,MAAM,CAACJ,GAAG,EAAE,CAAC,EAAE,IAAI1H,WAAW,CAACuF,KAAK,CAACiC,KAAK,EAAEzG,KAAK,CAAC,EAAE,IAAIf,WAAW,CAACe,KAAK,GAAG,CAAC,EAAEwE,KAAK,CAACsC,YAAY,CAAC,CAAC;UACpH;QACJ;MACJ;IACJ;EAAC;IAAA/G,GAAA;IAAAC,KAAA,EACD,SAAAqE,SAASG,KAAK,EAAE;MACZvF,WAAW,CAACoF,QAAQ,CAACG,KAAK,EAAE,IAAI,CAACgC,OAAO,CAAC;IAC7C;EAAC;IAAAzG,GAAA;IAAAC,KAAA,EACD,SAAA0E,kBAAkBF,KAAK,EAAEwC,SAAS,EAAE;MAChC,IAAIC,2BAA2B,GAAG,CAAC;MACnC,OAAO,EAAEA,2BAA2B,IAAI,IAAI,CAACT,OAAO,CAAClE,MAAM,IAAIkC,KAAK,CAACiC,KAAK,IAAI,IAAI,CAACD,OAAO,CAACS,2BAA2B,CAAC,CAACH,YAAY,CAAC,EAAE;QACnIG,2BAA2B,EAAE;MACjC;MACA,IAAIC,eAAe,GAAGD,2BAA2B;MACjD,OAAO,EAAEC,eAAe,IAAI,IAAI,CAACV,OAAO,CAAClE,MAAM,IAAIkC,KAAK,CAACsC,YAAY,GAAG,IAAI,CAACN,OAAO,CAACU,eAAe,CAAC,CAACT,KAAK,CAAC,EAAE;QAC1GS,eAAe,EAAE;MACrB;MACA,IAAMC,KAAK,GAAGH,SAAS,GAAGxC,KAAK,CAAClC,MAAM;MACtC,KAAK,IAAIoB,CAAC,GAAGwD,eAAe,EAAExD,CAAC,GAAG,IAAI,CAAC8C,OAAO,CAAClE,MAAM,EAAEoB,CAAC,EAAE,EAAE;QACxD,IAAI,CAAC8C,OAAO,CAAC9C,CAAC,CAAC,GAAG,IAAI,CAAC8C,OAAO,CAAC9C,CAAC,CAAC,CAACyD,KAAK,CAACA,KAAK,CAAC;MAClD;MACA,IAAIF,2BAA2B,KAAKC,eAAe,EAAE;QACjD,IAAME,QAAQ,GAAG,IAAInI,WAAW,CAACuF,KAAK,CAACiC,KAAK,EAAEjC,KAAK,CAACiC,KAAK,GAAGO,SAAS,CAAC;QACtE,IAAI,CAACI,QAAQ,CAACC,OAAO,EAAE;UACnB,IAAI,CAACb,OAAO,CAACO,MAAM,CAACE,2BAA2B,EAAE,CAAC,EAAEG,QAAQ,CAAC;QACjE;MACJ,CAAC,MACI;QACD,IAAMX,KAAK,GAAGa,IAAI,CAACxB,GAAG,CAACtB,KAAK,CAACiC,KAAK,EAAE,IAAI,CAACD,OAAO,CAACS,2BAA2B,CAAC,CAACR,KAAK,CAAC;QACpF,IAAMc,KAAK,GAAGD,IAAI,CAACE,GAAG,CAAChD,KAAK,CAACsC,YAAY,EAAE,IAAI,CAACN,OAAO,CAACU,eAAe,GAAG,CAAC,CAAC,CAACJ,YAAY,CAAC;QAC1F,IAAMM,SAAQ,GAAG,IAAInI,WAAW,CAACwH,KAAK,EAAEc,KAAK,GAAGJ,KAAK,CAAC;QACtD,IAAI,CAACC,SAAQ,CAACC,OAAO,EAAE;UACnB,IAAI,CAACb,OAAO,CAACO,MAAM,CAACE,2BAA2B,EAAEC,eAAe,GAAGD,2BAA2B,EAAEG,SAAQ,CAAC;QAC7G,CAAC,MACI;UACD,IAAI,CAACZ,OAAO,CAACO,MAAM,CAACE,2BAA2B,EAAEC,eAAe,GAAGD,2BAA2B,CAAC;QACnG;MACJ;IACJ;EAAC;IAAAlH,GAAA;IAAAC,KAAA,EACD,SAAAyH,SAAA,EAAW;MACP,OAAO,IAAI,CAACjB,OAAO,CAACkB,GAAG,CAAC,UAAAxG,CAAC;QAAA,OAAIA,CAAC,CAACuG,QAAQ,CAAC,CAAC;MAAA,EAAC,CAACE,IAAI,CAAC,KAAK,CAAC;IAC1D;EAAC;AAAA;AAEL,SAASxG,YAAYA,CAACyG,eAAe,EAAE/G,UAAU,EAAErB,mBAAmB,EAAEwB,IAAI,EAAE6G,MAAM,EAAExE,KAAK,EAAE;EACzF,IAAInC,CAAC,GAAG,IAAI;EACZ,IAAI1B,mBAAmB,EAAE;IACrB,IAAI;MACA0B,CAAC,GAAG1B,mBAAmB,CAACsI,eAAe,CAAC9G,IAAI,EAAE6G,MAAM,EAAExE,KAAK,CAAC0E,KAAK,CAAC,CAAC,CAAC;IACxE,CAAC,CACD,OAAOrC,CAAC,EAAE;MACN9G,iBAAiB,CAAC8G,CAAC,CAAC;IACxB;EACJ;EACA,IAAI,CAACxE,CAAC,EAAE;IACJA,CAAC,GAAGhC,mBAAmB,CAAC0I,eAAe,CAACI,gBAAgB,CAACnH,UAAU,CAAC,EAAEwC,KAAK,CAAC;EAChF;EACAhE,UAAU,CAAC4I,kBAAkB,CAAC/G,CAAC,CAACI,MAAM,EAAEN,IAAI,CAACsB,MAAM,CAAC;EACpD,OAAOpB,CAAC;AACZ;AACA,WAAagH,0BAA0B;EACnC,SAAAA,2BAAYC,wBAAwB,EAAEC,qBAAqB,EAAE;IAAA3I,eAAA,OAAAyI,0BAAA;IACzD,IAAI,CAACC,wBAAwB,GAAGA,wBAAwB;IACxD,IAAI,CAACC,qBAAqB,GAAGA,qBAAqB;IAClD,IAAI,CAACC,WAAW,GAAG,KAAK;IACxB,IAAI,CAACC,YAAY,GAAG,KAAK;EAC7B;EAAC,OAAAxI,YAAA,CAAAoI,0BAAA;IAAAnI,GAAA;IAAAC,KAAA,EACD,SAAAuI,QAAA,EAAU;MACN,IAAI,CAACF,WAAW,GAAG,IAAI;IAC3B;EAAC;IAAAtI,GAAA;IAAAC,KAAA,EACD,SAAAwI,cAAA,EAAgB;MACZ,IAAI,CAACC,4BAA4B,CAAC,CAAC;IACvC;EAAC;IAAA1I,GAAA;IAAAC,KAAA,EACD,SAAAyI,6BAAA,EAA+B;MAAA,IAAAC,MAAA;MAC3B,IAAI,IAAI,CAACJ,YAAY,IAAI,CAAC,IAAI,CAACH,wBAAwB,CAAC7H,UAAU,CAACqI,kBAAkB,CAAC,CAAC,IAAI,CAAC,IAAI,CAACC,mBAAmB,CAAC,CAAC,EAAE;QACpH;MACJ;MACA,IAAI,CAACN,YAAY,GAAG,IAAI;MACxB5J,iBAAiB,CAAC,UAACmK,QAAQ,EAAK;QAC5BH,MAAI,CAACJ,YAAY,GAAG,KAAK;QACzBI,MAAI,CAACI,+BAA+B,CAACD,QAAQ,CAAC;MAClD,CAAC,CAAC;IACN;IACA;AACJ;AACA;EAFI;IAAA9I,GAAA;IAAAC,KAAA,EAGA,SAAA8I,gCAAgCD,QAAQ,EAAE;MAAA,IAAAE,MAAA;MACtC;MACA;MACA,IAAMC,OAAO,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGL,QAAQ,CAACM,aAAa,CAAC,CAAC;MACrD,IAAMC,OAAO,GAAG,SAAVA,OAAOA,CAAA,EAAS;QAClB,IAAIL,MAAI,CAACV,WAAW,IAAI,CAACU,MAAI,CAACZ,wBAAwB,CAAC7H,UAAU,CAACqI,kBAAkB,CAAC,CAAC,IAAI,CAACI,MAAI,CAACH,mBAAmB,CAAC,CAAC,EAAE;UACnH;UACA;QACJ;QACAG,MAAI,CAACM,gCAAgC,CAAC,CAAC;QACvC,IAAIJ,IAAI,CAACC,GAAG,CAAC,CAAC,GAAGF,OAAO,EAAE;UACtB;UACA;UACAnK,WAAW,CAACuK,OAAO,CAAC;QACxB,CAAC,MACI;UACD;UACAL,MAAI,CAACN,4BAA4B,CAAC,CAAC;QACvC;MACJ,CAAC;MACDW,OAAO,CAAC,CAAC;IACb;IACA;AACJ;AACA;EAFI;IAAArJ,GAAA;IAAAC,KAAA,EAGA,SAAAqJ,iCAAA,EAAmC;MAC/B,IAAM9J,SAAS,GAAG,IAAI,CAAC4I,wBAAwB,CAAC7H,UAAU,CAACgJ,YAAY,CAAC,CAAC;MACzE,IAAM1I,OAAO,GAAG,IAAIxB,gCAAgC,CAAC,CAAC;MACtD,IAAMmK,EAAE,GAAGzK,SAAS,CAAC0K,MAAM,CAAC,KAAK,CAAC;MAClC,GAAG;QACC,IAAID,EAAE,CAACE,OAAO,CAAC,CAAC,GAAG,CAAC,EAAE;UAClB;UACA;UACA;UACA;QACJ;QACA,IAAMC,mBAAmB,GAAG,IAAI,CAACC,uBAAuB,CAAC/I,OAAO,CAAC;QACjE,IAAI8I,mBAAmB,IAAInK,SAAS,EAAE;UAClC;QACJ;MACJ,CAAC,QAAQ,IAAI,CAACqJ,mBAAmB,CAAC,CAAC;MACnC,IAAI,CAACR,qBAAqB,CAACwB,SAAS,CAAChJ,OAAO,CAACiJ,QAAQ,CAAC,CAAC,CAAC;MACxD,IAAI,CAACC,aAAa,CAAC,CAAC;IACxB;EAAC;IAAA/J,GAAA;IAAAC,KAAA,EACD,SAAA4I,oBAAA,EAAsB;MAClB,IAAI,CAAC,IAAI,CAACT,wBAAwB,EAAE;QAChC,OAAO,KAAK;MAChB;MACA,OAAO,CAAC,IAAI,CAACA,wBAAwB,CAACvI,KAAK,CAACqG,cAAc,CAAC,CAAC;IAChE;EAAC;IAAAlG,GAAA;IAAAC,KAAA,EACD,SAAA2J,wBAAwB/I,OAAO,EAAE;MAC7B,IAAImJ,EAAE;MACN,IAAMC,gBAAgB,GAAG,CAACD,EAAE,GAAG,IAAI,CAAC5B,wBAAwB,MAAM,IAAI,IAAI4B,EAAE,KAAK,KAAK,CAAC,GAAG,KAAK,CAAC,GAAGA,EAAE,CAAC5J,mBAAmB,CAAC,CAAC;MAC3H,IAAI,CAAC6J,gBAAgB,EAAE;QACnB,OAAO,IAAI,CAAC7B,wBAAwB,CAAC7H,UAAU,CAACgJ,YAAY,CAAC,CAAC,GAAG,CAAC;MACtE;MACA,IAAI,CAACnB,wBAAwB,CAACxH,qBAAqB,CAACC,OAAO,EAAEoJ,gBAAgB,CAAC9J,UAAU,CAAC;MACzF,OAAO8J,gBAAgB,CAAC9J,UAAU;IACtC;EAAC;IAAAH,GAAA;IAAAC,KAAA,EACD,SAAA8J,cAAA,EAAgB;MACZ,IAAI,IAAI,CAACzB,WAAW,EAAE;QAClB;MACJ;MACA,IAAI,IAAI,CAACF,wBAAwB,CAACvI,KAAK,CAACqG,cAAc,CAAC,CAAC,EAAE;QACtD,IAAI,CAACmC,qBAAqB,CAAC6B,8BAA8B,CAAC,CAAC;MAC/D;IACJ;EAAC;IAAAlK,GAAA;IAAAC,KAAA,EACD,SAAAkK,cAAchH,eAAe,EAAEyB,sBAAsB,EAAE;MACnD,IAAI,CAACwD,wBAAwB,CAACvI,KAAK,CAACgG,uBAAuB,CAAC,IAAI5G,SAAS,CAACkE,eAAe,EAAEyB,sBAAsB,CAAC,CAAC;IACvH;EAAC;AAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}