{"ast":null,"code":"import _slicedToArray from \"/Users/yinger/Desktop/z95_exam_frontend/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";\nimport _classCallCheck from \"/Users/yinger/Desktop/z95_exam_frontend/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"/Users/yinger/Desktop/z95_exam_frontend/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport \"core-js/modules/es.error.cause.js\";\nimport \"core-js/modules/es.error.to-string.js\";\nimport \"core-js/modules/es.array.concat.js\";\nimport \"core-js/modules/es.array.join.js\";\nimport \"core-js/modules/es.array.push.js\";\nimport \"core-js/modules/es.array-buffer.slice.js\";\nimport \"core-js/modules/es.data-view.js\";\nimport \"core-js/modules/es.array-buffer.detached.js\";\nimport \"core-js/modules/es.array-buffer.transfer.js\";\nimport \"core-js/modules/es.array-buffer.transfer-to-fixed-length.js\";\nimport \"core-js/modules/es.date.to-string.js\";\nimport \"core-js/modules/es.object.to-string.js\";\nimport \"core-js/modules/es.regexp.exec.js\";\nimport \"core-js/modules/es.regexp.to-string.js\";\nimport \"core-js/modules/es.string.split.js\";\nimport \"core-js/modules/es.typed-array.uint32-array.js\";\nimport \"core-js/modules/es.typed-array.at.js\";\nimport \"core-js/modules/es.typed-array.copy-within.js\";\nimport \"core-js/modules/es.typed-array.every.js\";\nimport \"core-js/modules/es.typed-array.fill.js\";\nimport \"core-js/modules/es.typed-array.filter.js\";\nimport \"core-js/modules/es.typed-array.find.js\";\nimport \"core-js/modules/es.typed-array.find-index.js\";\nimport \"core-js/modules/es.typed-array.find-last.js\";\nimport \"core-js/modules/es.typed-array.find-last-index.js\";\nimport \"core-js/modules/es.typed-array.for-each.js\";\nimport \"core-js/modules/es.typed-array.includes.js\";\nimport \"core-js/modules/es.typed-array.index-of.js\";\nimport \"core-js/modules/es.typed-array.iterator.js\";\nimport \"core-js/modules/es.typed-array.join.js\";\nimport \"core-js/modules/es.typed-array.last-index-of.js\";\nimport \"core-js/modules/es.typed-array.map.js\";\nimport \"core-js/modules/es.typed-array.reduce.js\";\nimport \"core-js/modules/es.typed-array.reduce-right.js\";\nimport \"core-js/modules/es.typed-array.reverse.js\";\nimport \"core-js/modules/es.typed-array.set.js\";\nimport \"core-js/modules/es.typed-array.slice.js\";\nimport \"core-js/modules/es.typed-array.some.js\";\nimport \"core-js/modules/es.typed-array.sort.js\";\nimport \"core-js/modules/es.typed-array.subarray.js\";\nimport \"core-js/modules/es.typed-array.to-locale-string.js\";\nimport \"core-js/modules/es.typed-array.to-reversed.js\";\nimport \"core-js/modules/es.typed-array.to-sorted.js\";\nimport \"core-js/modules/es.typed-array.to-string.js\";\nimport \"core-js/modules/es.typed-array.with.js\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport { Position } from '../core/position.js';\nimport { Range } from '../core/range.js';\nimport { countEOL } from '../core/eolCounter.js';\n/**\n * Represents sparse tokens over a contiguous range of lines.\n */\nexport var SparseMultilineTokens = /*#__PURE__*/function () {\n  function SparseMultilineTokens(startLineNumber, tokens) {\n    _classCallCheck(this, SparseMultilineTokens);\n    this._startLineNumber = startLineNumber;\n    this._tokens = tokens;\n    this._endLineNumber = this._startLineNumber + this._tokens.getMaxDeltaLine();\n  }\n  return _createClass(SparseMultilineTokens, [{\n    key: \"startLineNumber\",\n    get:\n    /**\n     * (Inclusive) start line number for these tokens.\n     */\n    function get() {\n      return this._startLineNumber;\n    }\n    /**\n     * (Inclusive) end line number for these tokens.\n     */\n  }, {\n    key: \"endLineNumber\",\n    get: function get() {\n      return this._endLineNumber;\n    }\n  }, {\n    key: \"toString\",\n    value: function toString() {\n      return this._tokens.toString(this._startLineNumber);\n    }\n  }, {\n    key: \"_updateEndLineNumber\",\n    value: function _updateEndLineNumber() {\n      this._endLineNumber = this._startLineNumber + this._tokens.getMaxDeltaLine();\n    }\n  }, {\n    key: \"isEmpty\",\n    value: function isEmpty() {\n      return this._tokens.isEmpty();\n    }\n  }, {\n    key: \"getLineTokens\",\n    value: function getLineTokens(lineNumber) {\n      if (this._startLineNumber <= lineNumber && lineNumber <= this._endLineNumber) {\n        return this._tokens.getLineTokens(lineNumber - this._startLineNumber);\n      }\n      return null;\n    }\n  }, {\n    key: \"getRange\",\n    value: function getRange() {\n      var deltaRange = this._tokens.getRange();\n      if (!deltaRange) {\n        return deltaRange;\n      }\n      return new Range(this._startLineNumber + deltaRange.startLineNumber, deltaRange.startColumn, this._startLineNumber + deltaRange.endLineNumber, deltaRange.endColumn);\n    }\n  }, {\n    key: \"removeTokens\",\n    value: function removeTokens(range) {\n      var startLineIndex = range.startLineNumber - this._startLineNumber;\n      var endLineIndex = range.endLineNumber - this._startLineNumber;\n      this._startLineNumber += this._tokens.removeTokens(startLineIndex, range.startColumn - 1, endLineIndex, range.endColumn - 1);\n      this._updateEndLineNumber();\n    }\n  }, {\n    key: \"split\",\n    value: function split(range) {\n      // split tokens to two:\n      // a) all the tokens before `range`\n      // b) all the tokens after `range`\n      var startLineIndex = range.startLineNumber - this._startLineNumber;\n      var endLineIndex = range.endLineNumber - this._startLineNumber;\n      var _this$_tokens$split = this._tokens.split(startLineIndex, range.startColumn - 1, endLineIndex, range.endColumn - 1),\n        _this$_tokens$split2 = _slicedToArray(_this$_tokens$split, 3),\n        a = _this$_tokens$split2[0],\n        b = _this$_tokens$split2[1],\n        bDeltaLine = _this$_tokens$split2[2];\n      return [new SparseMultilineTokens(this._startLineNumber, a), new SparseMultilineTokens(this._startLineNumber + bDeltaLine, b)];\n    }\n  }, {\n    key: \"applyEdit\",\n    value: function applyEdit(range, text) {\n      var _countEOL = countEOL(text),\n        _countEOL2 = _slicedToArray(_countEOL, 3),\n        eolCount = _countEOL2[0],\n        firstLineLength = _countEOL2[1],\n        lastLineLength = _countEOL2[2];\n      this.acceptEdit(range, eolCount, firstLineLength, lastLineLength, text.length > 0 ? text.charCodeAt(0) : 0 /* CharCode.Null */);\n    }\n  }, {\n    key: \"acceptEdit\",\n    value: function acceptEdit(range, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n      this._acceptDeleteRange(range);\n      this._acceptInsertText(new Position(range.startLineNumber, range.startColumn), eolCount, firstLineLength, lastLineLength, firstCharCode);\n      this._updateEndLineNumber();\n    }\n  }, {\n    key: \"_acceptDeleteRange\",\n    value: function _acceptDeleteRange(range) {\n      if (range.startLineNumber === range.endLineNumber && range.startColumn === range.endColumn) {\n        // Nothing to delete\n        return;\n      }\n      var firstLineIndex = range.startLineNumber - this._startLineNumber;\n      var lastLineIndex = range.endLineNumber - this._startLineNumber;\n      if (lastLineIndex < 0) {\n        // this deletion occurs entirely before this block, so we only need to adjust line numbers\n        var deletedLinesCount = lastLineIndex - firstLineIndex;\n        this._startLineNumber -= deletedLinesCount;\n        return;\n      }\n      var tokenMaxDeltaLine = this._tokens.getMaxDeltaLine();\n      if (firstLineIndex >= tokenMaxDeltaLine + 1) {\n        // this deletion occurs entirely after this block, so there is nothing to do\n        return;\n      }\n      if (firstLineIndex < 0 && lastLineIndex >= tokenMaxDeltaLine + 1) {\n        // this deletion completely encompasses this block\n        this._startLineNumber = 0;\n        this._tokens.clear();\n        return;\n      }\n      if (firstLineIndex < 0) {\n        var deletedBefore = -firstLineIndex;\n        this._startLineNumber -= deletedBefore;\n        this._tokens.acceptDeleteRange(range.startColumn - 1, 0, 0, lastLineIndex, range.endColumn - 1);\n      } else {\n        this._tokens.acceptDeleteRange(0, firstLineIndex, range.startColumn - 1, lastLineIndex, range.endColumn - 1);\n      }\n    }\n  }, {\n    key: \"_acceptInsertText\",\n    value: function _acceptInsertText(position, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n      if (eolCount === 0 && firstLineLength === 0) {\n        // Nothing to insert\n        return;\n      }\n      var lineIndex = position.lineNumber - this._startLineNumber;\n      if (lineIndex < 0) {\n        // this insertion occurs before this block, so we only need to adjust line numbers\n        this._startLineNumber += eolCount;\n        return;\n      }\n      var tokenMaxDeltaLine = this._tokens.getMaxDeltaLine();\n      if (lineIndex >= tokenMaxDeltaLine + 1) {\n        // this insertion occurs after this block, so there is nothing to do\n        return;\n      }\n      this._tokens.acceptInsertText(lineIndex, position.column - 1, eolCount, firstLineLength, lastLineLength, firstCharCode);\n    }\n  }], [{\n    key: \"create\",\n    value: function create(startLineNumber, tokens) {\n      return new SparseMultilineTokens(startLineNumber, new SparseMultilineTokensStorage(tokens));\n    }\n  }]);\n}();\nvar SparseMultilineTokensStorage = /*#__PURE__*/function () {\n  function SparseMultilineTokensStorage(tokens) {\n    _classCallCheck(this, SparseMultilineTokensStorage);\n    this._tokens = tokens;\n    this._tokenCount = tokens.length / 4;\n  }\n  return _createClass(SparseMultilineTokensStorage, [{\n    key: \"toString\",\n    value: function toString(startLineNumber) {\n      var pieces = [];\n      for (var i = 0; i < this._tokenCount; i++) {\n        pieces.push(\"(\".concat(this._getDeltaLine(i) + startLineNumber, \",\").concat(this._getStartCharacter(i), \"-\").concat(this._getEndCharacter(i), \")\"));\n      }\n      return \"[\".concat(pieces.join(','), \"]\");\n    }\n  }, {\n    key: \"getMaxDeltaLine\",\n    value: function getMaxDeltaLine() {\n      var tokenCount = this._getTokenCount();\n      if (tokenCount === 0) {\n        return -1;\n      }\n      return this._getDeltaLine(tokenCount - 1);\n    }\n  }, {\n    key: \"getRange\",\n    value: function getRange() {\n      var tokenCount = this._getTokenCount();\n      if (tokenCount === 0) {\n        return null;\n      }\n      var startChar = this._getStartCharacter(0);\n      var maxDeltaLine = this._getDeltaLine(tokenCount - 1);\n      var endChar = this._getEndCharacter(tokenCount - 1);\n      return new Range(0, startChar + 1, maxDeltaLine, endChar + 1);\n    }\n  }, {\n    key: \"_getTokenCount\",\n    value: function _getTokenCount() {\n      return this._tokenCount;\n    }\n  }, {\n    key: \"_getDeltaLine\",\n    value: function _getDeltaLine(tokenIndex) {\n      return this._tokens[4 * tokenIndex];\n    }\n  }, {\n    key: \"_getStartCharacter\",\n    value: function _getStartCharacter(tokenIndex) {\n      return this._tokens[4 * tokenIndex + 1];\n    }\n  }, {\n    key: \"_getEndCharacter\",\n    value: function _getEndCharacter(tokenIndex) {\n      return this._tokens[4 * tokenIndex + 2];\n    }\n  }, {\n    key: \"isEmpty\",\n    value: function isEmpty() {\n      return this._getTokenCount() === 0;\n    }\n  }, {\n    key: \"getLineTokens\",\n    value: function getLineTokens(deltaLine) {\n      var low = 0;\n      var high = this._getTokenCount() - 1;\n      while (low < high) {\n        var mid = low + Math.floor((high - low) / 2);\n        var midDeltaLine = this._getDeltaLine(mid);\n        if (midDeltaLine < deltaLine) {\n          low = mid + 1;\n        } else if (midDeltaLine > deltaLine) {\n          high = mid - 1;\n        } else {\n          var min = mid;\n          while (min > low && this._getDeltaLine(min - 1) === deltaLine) {\n            min--;\n          }\n          var max = mid;\n          while (max < high && this._getDeltaLine(max + 1) === deltaLine) {\n            max++;\n          }\n          return new SparseLineTokens(this._tokens.subarray(4 * min, 4 * max + 4));\n        }\n      }\n      if (this._getDeltaLine(low) === deltaLine) {\n        return new SparseLineTokens(this._tokens.subarray(4 * low, 4 * low + 4));\n      }\n      return null;\n    }\n  }, {\n    key: \"clear\",\n    value: function clear() {\n      this._tokenCount = 0;\n    }\n  }, {\n    key: \"removeTokens\",\n    value: function removeTokens(startDeltaLine, startChar, endDeltaLine, endChar) {\n      var tokens = this._tokens;\n      var tokenCount = this._tokenCount;\n      var newTokenCount = 0;\n      var hasDeletedTokens = false;\n      var firstDeltaLine = 0;\n      for (var i = 0; i < tokenCount; i++) {\n        var srcOffset = 4 * i;\n        var tokenDeltaLine = tokens[srcOffset];\n        var tokenStartCharacter = tokens[srcOffset + 1];\n        var tokenEndCharacter = tokens[srcOffset + 2];\n        var tokenMetadata = tokens[srcOffset + 3];\n        if ((tokenDeltaLine > startDeltaLine || tokenDeltaLine === startDeltaLine && tokenEndCharacter >= startChar) && (tokenDeltaLine < endDeltaLine || tokenDeltaLine === endDeltaLine && tokenStartCharacter <= endChar)) {\n          hasDeletedTokens = true;\n        } else {\n          if (newTokenCount === 0) {\n            firstDeltaLine = tokenDeltaLine;\n          }\n          if (hasDeletedTokens) {\n            // must move the token to the left\n            var destOffset = 4 * newTokenCount;\n            tokens[destOffset] = tokenDeltaLine - firstDeltaLine;\n            tokens[destOffset + 1] = tokenStartCharacter;\n            tokens[destOffset + 2] = tokenEndCharacter;\n            tokens[destOffset + 3] = tokenMetadata;\n          }\n          newTokenCount++;\n        }\n      }\n      this._tokenCount = newTokenCount;\n      return firstDeltaLine;\n    }\n  }, {\n    key: \"split\",\n    value: function split(startDeltaLine, startChar, endDeltaLine, endChar) {\n      var tokens = this._tokens;\n      var tokenCount = this._tokenCount;\n      var aTokens = [];\n      var bTokens = [];\n      var destTokens = aTokens;\n      var destOffset = 0;\n      var destFirstDeltaLine = 0;\n      for (var i = 0; i < tokenCount; i++) {\n        var srcOffset = 4 * i;\n        var tokenDeltaLine = tokens[srcOffset];\n        var tokenStartCharacter = tokens[srcOffset + 1];\n        var tokenEndCharacter = tokens[srcOffset + 2];\n        var tokenMetadata = tokens[srcOffset + 3];\n        if (tokenDeltaLine > startDeltaLine || tokenDeltaLine === startDeltaLine && tokenEndCharacter >= startChar) {\n          if (tokenDeltaLine < endDeltaLine || tokenDeltaLine === endDeltaLine && tokenStartCharacter <= endChar) {\n            // this token is touching the range\n            continue;\n          } else {\n            // this token is after the range\n            if (destTokens !== bTokens) {\n              // this token is the first token after the range\n              destTokens = bTokens;\n              destOffset = 0;\n              destFirstDeltaLine = tokenDeltaLine;\n            }\n          }\n        }\n        destTokens[destOffset++] = tokenDeltaLine - destFirstDeltaLine;\n        destTokens[destOffset++] = tokenStartCharacter;\n        destTokens[destOffset++] = tokenEndCharacter;\n        destTokens[destOffset++] = tokenMetadata;\n      }\n      return [new SparseMultilineTokensStorage(new Uint32Array(aTokens)), new SparseMultilineTokensStorage(new Uint32Array(bTokens)), destFirstDeltaLine];\n    }\n  }, {\n    key: \"acceptDeleteRange\",\n    value: function acceptDeleteRange(horizontalShiftForFirstLineTokens, startDeltaLine, startCharacter, endDeltaLine, endCharacter) {\n      // This is a bit complex, here are the cases I used to think about this:\n      //\n      // 1. The token starts before the deletion range\n      // 1a. The token is completely before the deletion range\n      //               -----------\n      //                          xxxxxxxxxxx\n      // 1b. The token starts before, the deletion range ends after the token\n      //               -----------\n      //                      xxxxxxxxxxx\n      // 1c. The token starts before, the deletion range ends precisely with the token\n      //               ---------------\n      //                      xxxxxxxx\n      // 1d. The token starts before, the deletion range is inside the token\n      //               ---------------\n      //                    xxxxx\n      //\n      // 2. The token starts at the same position with the deletion range\n      // 2a. The token starts at the same position, and ends inside the deletion range\n      //               -------\n      //               xxxxxxxxxxx\n      // 2b. The token starts at the same position, and ends at the same position as the deletion range\n      //               ----------\n      //               xxxxxxxxxx\n      // 2c. The token starts at the same position, and ends after the deletion range\n      //               -------------\n      //               xxxxxxx\n      //\n      // 3. The token starts inside the deletion range\n      // 3a. The token is inside the deletion range\n      //                -------\n      //             xxxxxxxxxxxxx\n      // 3b. The token starts inside the deletion range, and ends at the same position as the deletion range\n      //                ----------\n      //             xxxxxxxxxxxxx\n      // 3c. The token starts inside the deletion range, and ends after the deletion range\n      //                ------------\n      //             xxxxxxxxxxx\n      //\n      // 4. The token starts after the deletion range\n      //                  -----------\n      //          xxxxxxxx\n      //\n      var tokens = this._tokens;\n      var tokenCount = this._tokenCount;\n      var deletedLineCount = endDeltaLine - startDeltaLine;\n      var newTokenCount = 0;\n      var hasDeletedTokens = false;\n      for (var i = 0; i < tokenCount; i++) {\n        var srcOffset = 4 * i;\n        var tokenDeltaLine = tokens[srcOffset];\n        var tokenStartCharacter = tokens[srcOffset + 1];\n        var tokenEndCharacter = tokens[srcOffset + 2];\n        var tokenMetadata = tokens[srcOffset + 3];\n        if (tokenDeltaLine < startDeltaLine || tokenDeltaLine === startDeltaLine && tokenEndCharacter <= startCharacter) {\n          // 1a. The token is completely before the deletion range\n          // => nothing to do\n          newTokenCount++;\n          continue;\n        } else if (tokenDeltaLine === startDeltaLine && tokenStartCharacter < startCharacter) {\n          // 1b, 1c, 1d\n          // => the token survives, but it needs to shrink\n          if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n            // 1d. The token starts before, the deletion range is inside the token\n            // => the token shrinks by the deletion character count\n            tokenEndCharacter -= endCharacter - startCharacter;\n          } else {\n            // 1b. The token starts before, the deletion range ends after the token\n            // 1c. The token starts before, the deletion range ends precisely with the token\n            // => the token shrinks its ending to the deletion start\n            tokenEndCharacter = startCharacter;\n          }\n        } else if (tokenDeltaLine === startDeltaLine && tokenStartCharacter === startCharacter) {\n          // 2a, 2b, 2c\n          if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n            // 2c. The token starts at the same position, and ends after the deletion range\n            // => the token shrinks by the deletion character count\n            tokenEndCharacter -= endCharacter - startCharacter;\n          } else {\n            // 2a. The token starts at the same position, and ends inside the deletion range\n            // 2b. The token starts at the same position, and ends at the same position as the deletion range\n            // => the token is deleted\n            hasDeletedTokens = true;\n            continue;\n          }\n        } else if (tokenDeltaLine < endDeltaLine || tokenDeltaLine === endDeltaLine && tokenStartCharacter < endCharacter) {\n          // 3a, 3b, 3c\n          if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n            // 3c. The token starts inside the deletion range, and ends after the deletion range\n            // => the token moves to continue right after the deletion\n            tokenDeltaLine = startDeltaLine;\n            tokenStartCharacter = startCharacter;\n            tokenEndCharacter = tokenStartCharacter + (tokenEndCharacter - endCharacter);\n          } else {\n            // 3a. The token is inside the deletion range\n            // 3b. The token starts inside the deletion range, and ends at the same position as the deletion range\n            // => the token is deleted\n            hasDeletedTokens = true;\n            continue;\n          }\n        } else if (tokenDeltaLine > endDeltaLine) {\n          // 4. (partial) The token starts after the deletion range, on a line below...\n          if (deletedLineCount === 0 && !hasDeletedTokens) {\n            // early stop, there is no need to walk all the tokens and do nothing...\n            newTokenCount = tokenCount;\n            break;\n          }\n          tokenDeltaLine -= deletedLineCount;\n        } else if (tokenDeltaLine === endDeltaLine && tokenStartCharacter >= endCharacter) {\n          // 4. (continued) The token starts after the deletion range, on the last line where a deletion occurs\n          if (horizontalShiftForFirstLineTokens && tokenDeltaLine === 0) {\n            tokenStartCharacter += horizontalShiftForFirstLineTokens;\n            tokenEndCharacter += horizontalShiftForFirstLineTokens;\n          }\n          tokenDeltaLine -= deletedLineCount;\n          tokenStartCharacter -= endCharacter - startCharacter;\n          tokenEndCharacter -= endCharacter - startCharacter;\n        } else {\n          throw new Error(\"Not possible!\");\n        }\n        var destOffset = 4 * newTokenCount;\n        tokens[destOffset] = tokenDeltaLine;\n        tokens[destOffset + 1] = tokenStartCharacter;\n        tokens[destOffset + 2] = tokenEndCharacter;\n        tokens[destOffset + 3] = tokenMetadata;\n        newTokenCount++;\n      }\n      this._tokenCount = newTokenCount;\n    }\n  }, {\n    key: \"acceptInsertText\",\n    value: function acceptInsertText(deltaLine, character, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n      // Here are the cases I used to think about this:\n      //\n      // 1. The token is completely before the insertion point\n      //            -----------   |\n      // 2. The token ends precisely at the insertion point\n      //            -----------|\n      // 3. The token contains the insertion point\n      //            -----|------\n      // 4. The token starts precisely at the insertion point\n      //            |-----------\n      // 5. The token is completely after the insertion point\n      //            |   -----------\n      //\n      var isInsertingPreciselyOneWordCharacter = eolCount === 0 && firstLineLength === 1 && (firstCharCode >= 48 /* CharCode.Digit0 */ && firstCharCode <= 57 /* CharCode.Digit9 */ || firstCharCode >= 65 /* CharCode.A */ && firstCharCode <= 90 /* CharCode.Z */ || firstCharCode >= 97 /* CharCode.a */ && firstCharCode <= 122 /* CharCode.z */);\n      var tokens = this._tokens;\n      var tokenCount = this._tokenCount;\n      for (var i = 0; i < tokenCount; i++) {\n        var offset = 4 * i;\n        var tokenDeltaLine = tokens[offset];\n        var tokenStartCharacter = tokens[offset + 1];\n        var tokenEndCharacter = tokens[offset + 2];\n        if (tokenDeltaLine < deltaLine || tokenDeltaLine === deltaLine && tokenEndCharacter < character) {\n          // 1. The token is completely before the insertion point\n          // => nothing to do\n          continue;\n        } else if (tokenDeltaLine === deltaLine && tokenEndCharacter === character) {\n          // 2. The token ends precisely at the insertion point\n          // => expand the end character only if inserting precisely one character that is a word character\n          if (isInsertingPreciselyOneWordCharacter) {\n            tokenEndCharacter += 1;\n          } else {\n            continue;\n          }\n        } else if (tokenDeltaLine === deltaLine && tokenStartCharacter < character && character < tokenEndCharacter) {\n          // 3. The token contains the insertion point\n          if (eolCount === 0) {\n            // => just expand the end character\n            tokenEndCharacter += firstLineLength;\n          } else {\n            // => cut off the token\n            tokenEndCharacter = character;\n          }\n        } else {\n          // 4. or 5.\n          if (tokenDeltaLine === deltaLine && tokenStartCharacter === character) {\n            // 4. The token starts precisely at the insertion point\n            // => grow the token (by keeping its start constant) only if inserting precisely one character that is a word character\n            // => otherwise behave as in case 5.\n            if (isInsertingPreciselyOneWordCharacter) {\n              continue;\n            }\n          }\n          // => the token must move and keep its size constant\n          if (tokenDeltaLine === deltaLine) {\n            tokenDeltaLine += eolCount;\n            // this token is on the line where the insertion is taking place\n            if (eolCount === 0) {\n              tokenStartCharacter += firstLineLength;\n              tokenEndCharacter += firstLineLength;\n            } else {\n              var tokenLength = tokenEndCharacter - tokenStartCharacter;\n              tokenStartCharacter = lastLineLength + (tokenStartCharacter - character);\n              tokenEndCharacter = tokenStartCharacter + tokenLength;\n            }\n          } else {\n            tokenDeltaLine += eolCount;\n          }\n        }\n        tokens[offset] = tokenDeltaLine;\n        tokens[offset + 1] = tokenStartCharacter;\n        tokens[offset + 2] = tokenEndCharacter;\n      }\n    }\n  }]);\n}();\nexport var SparseLineTokens = /*#__PURE__*/function () {\n  function SparseLineTokens(tokens) {\n    _classCallCheck(this, SparseLineTokens);\n    this._tokens = tokens;\n  }\n  return _createClass(SparseLineTokens, [{\n    key: \"getCount\",\n    value: function getCount() {\n      return this._tokens.length / 4;\n    }\n  }, {\n    key: \"getStartCharacter\",\n    value: function getStartCharacter(tokenIndex) {\n      return this._tokens[4 * tokenIndex + 1];\n    }\n  }, {\n    key: \"getEndCharacter\",\n    value: function getEndCharacter(tokenIndex) {\n      return this._tokens[4 * tokenIndex + 2];\n    }\n  }, {\n    key: \"getMetadata\",\n    value: function getMetadata(tokenIndex) {\n      return this._tokens[4 * tokenIndex + 3];\n    }\n  }]);\n}();","map":{"version":3,"names":["Position","Range","countEOL","SparseMultilineTokens","startLineNumber","tokens","_classCallCheck","_startLineNumber","_tokens","_endLineNumber","getMaxDeltaLine","_createClass","key","get","value","toString","_updateEndLineNumber","isEmpty","getLineTokens","lineNumber","getRange","deltaRange","startColumn","endLineNumber","endColumn","removeTokens","range","startLineIndex","endLineIndex","split","_this$_tokens$split","_this$_tokens$split2","_slicedToArray","a","b","bDeltaLine","applyEdit","text","_countEOL","_countEOL2","eolCount","firstLineLength","lastLineLength","acceptEdit","length","charCodeAt","firstCharCode","_acceptDeleteRange","_acceptInsertText","firstLineIndex","lastLineIndex","deletedLinesCount","tokenMaxDeltaLine","clear","deletedBefore","acceptDeleteRange","position","lineIndex","acceptInsertText","column","create","SparseMultilineTokensStorage","_tokenCount","pieces","i","push","concat","_getDeltaLine","_getStartCharacter","_getEndCharacter","join","tokenCount","_getTokenCount","startChar","maxDeltaLine","endChar","tokenIndex","deltaLine","low","high","mid","Math","floor","midDeltaLine","min","max","SparseLineTokens","subarray","startDeltaLine","endDeltaLine","newTokenCount","hasDeletedTokens","firstDeltaLine","srcOffset","tokenDeltaLine","tokenStartCharacter","tokenEndCharacter","tokenMetadata","destOffset","aTokens","bTokens","destTokens","destFirstDeltaLine","Uint32Array","horizontalShiftForFirstLineTokens","startCharacter","endCharacter","deletedLineCount","Error","character","isInsertingPreciselyOneWordCharacter","offset","tokenLength","getCount","getStartCharacter","getEndCharacter","getMetadata"],"sources":["/Users/yinger/Desktop/z95_exam_frontend/node_modules/monaco-editor/esm/vs/editor/common/tokens/sparseMultilineTokens.js"],"sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nimport { Position } from '../core/position.js';\nimport { Range } from '../core/range.js';\nimport { countEOL } from '../core/eolCounter.js';\n/**\n * Represents sparse tokens over a contiguous range of lines.\n */\nexport class SparseMultilineTokens {\n    static create(startLineNumber, tokens) {\n        return new SparseMultilineTokens(startLineNumber, new SparseMultilineTokensStorage(tokens));\n    }\n    /**\n     * (Inclusive) start line number for these tokens.\n     */\n    get startLineNumber() {\n        return this._startLineNumber;\n    }\n    /**\n     * (Inclusive) end line number for these tokens.\n     */\n    get endLineNumber() {\n        return this._endLineNumber;\n    }\n    constructor(startLineNumber, tokens) {\n        this._startLineNumber = startLineNumber;\n        this._tokens = tokens;\n        this._endLineNumber = this._startLineNumber + this._tokens.getMaxDeltaLine();\n    }\n    toString() {\n        return this._tokens.toString(this._startLineNumber);\n    }\n    _updateEndLineNumber() {\n        this._endLineNumber = this._startLineNumber + this._tokens.getMaxDeltaLine();\n    }\n    isEmpty() {\n        return this._tokens.isEmpty();\n    }\n    getLineTokens(lineNumber) {\n        if (this._startLineNumber <= lineNumber && lineNumber <= this._endLineNumber) {\n            return this._tokens.getLineTokens(lineNumber - this._startLineNumber);\n        }\n        return null;\n    }\n    getRange() {\n        const deltaRange = this._tokens.getRange();\n        if (!deltaRange) {\n            return deltaRange;\n        }\n        return new Range(this._startLineNumber + deltaRange.startLineNumber, deltaRange.startColumn, this._startLineNumber + deltaRange.endLineNumber, deltaRange.endColumn);\n    }\n    removeTokens(range) {\n        const startLineIndex = range.startLineNumber - this._startLineNumber;\n        const endLineIndex = range.endLineNumber - this._startLineNumber;\n        this._startLineNumber += this._tokens.removeTokens(startLineIndex, range.startColumn - 1, endLineIndex, range.endColumn - 1);\n        this._updateEndLineNumber();\n    }\n    split(range) {\n        // split tokens to two:\n        // a) all the tokens before `range`\n        // b) all the tokens after `range`\n        const startLineIndex = range.startLineNumber - this._startLineNumber;\n        const endLineIndex = range.endLineNumber - this._startLineNumber;\n        const [a, b, bDeltaLine] = this._tokens.split(startLineIndex, range.startColumn - 1, endLineIndex, range.endColumn - 1);\n        return [new SparseMultilineTokens(this._startLineNumber, a), new SparseMultilineTokens(this._startLineNumber + bDeltaLine, b)];\n    }\n    applyEdit(range, text) {\n        const [eolCount, firstLineLength, lastLineLength] = countEOL(text);\n        this.acceptEdit(range, eolCount, firstLineLength, lastLineLength, text.length > 0 ? text.charCodeAt(0) : 0 /* CharCode.Null */);\n    }\n    acceptEdit(range, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n        this._acceptDeleteRange(range);\n        this._acceptInsertText(new Position(range.startLineNumber, range.startColumn), eolCount, firstLineLength, lastLineLength, firstCharCode);\n        this._updateEndLineNumber();\n    }\n    _acceptDeleteRange(range) {\n        if (range.startLineNumber === range.endLineNumber && range.startColumn === range.endColumn) {\n            // Nothing to delete\n            return;\n        }\n        const firstLineIndex = range.startLineNumber - this._startLineNumber;\n        const lastLineIndex = range.endLineNumber - this._startLineNumber;\n        if (lastLineIndex < 0) {\n            // this deletion occurs entirely before this block, so we only need to adjust line numbers\n            const deletedLinesCount = lastLineIndex - firstLineIndex;\n            this._startLineNumber -= deletedLinesCount;\n            return;\n        }\n        const tokenMaxDeltaLine = this._tokens.getMaxDeltaLine();\n        if (firstLineIndex >= tokenMaxDeltaLine + 1) {\n            // this deletion occurs entirely after this block, so there is nothing to do\n            return;\n        }\n        if (firstLineIndex < 0 && lastLineIndex >= tokenMaxDeltaLine + 1) {\n            // this deletion completely encompasses this block\n            this._startLineNumber = 0;\n            this._tokens.clear();\n            return;\n        }\n        if (firstLineIndex < 0) {\n            const deletedBefore = -firstLineIndex;\n            this._startLineNumber -= deletedBefore;\n            this._tokens.acceptDeleteRange(range.startColumn - 1, 0, 0, lastLineIndex, range.endColumn - 1);\n        }\n        else {\n            this._tokens.acceptDeleteRange(0, firstLineIndex, range.startColumn - 1, lastLineIndex, range.endColumn - 1);\n        }\n    }\n    _acceptInsertText(position, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n        if (eolCount === 0 && firstLineLength === 0) {\n            // Nothing to insert\n            return;\n        }\n        const lineIndex = position.lineNumber - this._startLineNumber;\n        if (lineIndex < 0) {\n            // this insertion occurs before this block, so we only need to adjust line numbers\n            this._startLineNumber += eolCount;\n            return;\n        }\n        const tokenMaxDeltaLine = this._tokens.getMaxDeltaLine();\n        if (lineIndex >= tokenMaxDeltaLine + 1) {\n            // this insertion occurs after this block, so there is nothing to do\n            return;\n        }\n        this._tokens.acceptInsertText(lineIndex, position.column - 1, eolCount, firstLineLength, lastLineLength, firstCharCode);\n    }\n}\nclass SparseMultilineTokensStorage {\n    constructor(tokens) {\n        this._tokens = tokens;\n        this._tokenCount = tokens.length / 4;\n    }\n    toString(startLineNumber) {\n        const pieces = [];\n        for (let i = 0; i < this._tokenCount; i++) {\n            pieces.push(`(${this._getDeltaLine(i) + startLineNumber},${this._getStartCharacter(i)}-${this._getEndCharacter(i)})`);\n        }\n        return `[${pieces.join(',')}]`;\n    }\n    getMaxDeltaLine() {\n        const tokenCount = this._getTokenCount();\n        if (tokenCount === 0) {\n            return -1;\n        }\n        return this._getDeltaLine(tokenCount - 1);\n    }\n    getRange() {\n        const tokenCount = this._getTokenCount();\n        if (tokenCount === 0) {\n            return null;\n        }\n        const startChar = this._getStartCharacter(0);\n        const maxDeltaLine = this._getDeltaLine(tokenCount - 1);\n        const endChar = this._getEndCharacter(tokenCount - 1);\n        return new Range(0, startChar + 1, maxDeltaLine, endChar + 1);\n    }\n    _getTokenCount() {\n        return this._tokenCount;\n    }\n    _getDeltaLine(tokenIndex) {\n        return this._tokens[4 * tokenIndex];\n    }\n    _getStartCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 1];\n    }\n    _getEndCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 2];\n    }\n    isEmpty() {\n        return (this._getTokenCount() === 0);\n    }\n    getLineTokens(deltaLine) {\n        let low = 0;\n        let high = this._getTokenCount() - 1;\n        while (low < high) {\n            const mid = low + Math.floor((high - low) / 2);\n            const midDeltaLine = this._getDeltaLine(mid);\n            if (midDeltaLine < deltaLine) {\n                low = mid + 1;\n            }\n            else if (midDeltaLine > deltaLine) {\n                high = mid - 1;\n            }\n            else {\n                let min = mid;\n                while (min > low && this._getDeltaLine(min - 1) === deltaLine) {\n                    min--;\n                }\n                let max = mid;\n                while (max < high && this._getDeltaLine(max + 1) === deltaLine) {\n                    max++;\n                }\n                return new SparseLineTokens(this._tokens.subarray(4 * min, 4 * max + 4));\n            }\n        }\n        if (this._getDeltaLine(low) === deltaLine) {\n            return new SparseLineTokens(this._tokens.subarray(4 * low, 4 * low + 4));\n        }\n        return null;\n    }\n    clear() {\n        this._tokenCount = 0;\n    }\n    removeTokens(startDeltaLine, startChar, endDeltaLine, endChar) {\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        let newTokenCount = 0;\n        let hasDeletedTokens = false;\n        let firstDeltaLine = 0;\n        for (let i = 0; i < tokenCount; i++) {\n            const srcOffset = 4 * i;\n            const tokenDeltaLine = tokens[srcOffset];\n            const tokenStartCharacter = tokens[srcOffset + 1];\n            const tokenEndCharacter = tokens[srcOffset + 2];\n            const tokenMetadata = tokens[srcOffset + 3];\n            if ((tokenDeltaLine > startDeltaLine || (tokenDeltaLine === startDeltaLine && tokenEndCharacter >= startChar))\n                && (tokenDeltaLine < endDeltaLine || (tokenDeltaLine === endDeltaLine && tokenStartCharacter <= endChar))) {\n                hasDeletedTokens = true;\n            }\n            else {\n                if (newTokenCount === 0) {\n                    firstDeltaLine = tokenDeltaLine;\n                }\n                if (hasDeletedTokens) {\n                    // must move the token to the left\n                    const destOffset = 4 * newTokenCount;\n                    tokens[destOffset] = tokenDeltaLine - firstDeltaLine;\n                    tokens[destOffset + 1] = tokenStartCharacter;\n                    tokens[destOffset + 2] = tokenEndCharacter;\n                    tokens[destOffset + 3] = tokenMetadata;\n                }\n                newTokenCount++;\n            }\n        }\n        this._tokenCount = newTokenCount;\n        return firstDeltaLine;\n    }\n    split(startDeltaLine, startChar, endDeltaLine, endChar) {\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        const aTokens = [];\n        const bTokens = [];\n        let destTokens = aTokens;\n        let destOffset = 0;\n        let destFirstDeltaLine = 0;\n        for (let i = 0; i < tokenCount; i++) {\n            const srcOffset = 4 * i;\n            const tokenDeltaLine = tokens[srcOffset];\n            const tokenStartCharacter = tokens[srcOffset + 1];\n            const tokenEndCharacter = tokens[srcOffset + 2];\n            const tokenMetadata = tokens[srcOffset + 3];\n            if ((tokenDeltaLine > startDeltaLine || (tokenDeltaLine === startDeltaLine && tokenEndCharacter >= startChar))) {\n                if ((tokenDeltaLine < endDeltaLine || (tokenDeltaLine === endDeltaLine && tokenStartCharacter <= endChar))) {\n                    // this token is touching the range\n                    continue;\n                }\n                else {\n                    // this token is after the range\n                    if (destTokens !== bTokens) {\n                        // this token is the first token after the range\n                        destTokens = bTokens;\n                        destOffset = 0;\n                        destFirstDeltaLine = tokenDeltaLine;\n                    }\n                }\n            }\n            destTokens[destOffset++] = tokenDeltaLine - destFirstDeltaLine;\n            destTokens[destOffset++] = tokenStartCharacter;\n            destTokens[destOffset++] = tokenEndCharacter;\n            destTokens[destOffset++] = tokenMetadata;\n        }\n        return [new SparseMultilineTokensStorage(new Uint32Array(aTokens)), new SparseMultilineTokensStorage(new Uint32Array(bTokens)), destFirstDeltaLine];\n    }\n    acceptDeleteRange(horizontalShiftForFirstLineTokens, startDeltaLine, startCharacter, endDeltaLine, endCharacter) {\n        // This is a bit complex, here are the cases I used to think about this:\n        //\n        // 1. The token starts before the deletion range\n        // 1a. The token is completely before the deletion range\n        //               -----------\n        //                          xxxxxxxxxxx\n        // 1b. The token starts before, the deletion range ends after the token\n        //               -----------\n        //                      xxxxxxxxxxx\n        // 1c. The token starts before, the deletion range ends precisely with the token\n        //               ---------------\n        //                      xxxxxxxx\n        // 1d. The token starts before, the deletion range is inside the token\n        //               ---------------\n        //                    xxxxx\n        //\n        // 2. The token starts at the same position with the deletion range\n        // 2a. The token starts at the same position, and ends inside the deletion range\n        //               -------\n        //               xxxxxxxxxxx\n        // 2b. The token starts at the same position, and ends at the same position as the deletion range\n        //               ----------\n        //               xxxxxxxxxx\n        // 2c. The token starts at the same position, and ends after the deletion range\n        //               -------------\n        //               xxxxxxx\n        //\n        // 3. The token starts inside the deletion range\n        // 3a. The token is inside the deletion range\n        //                -------\n        //             xxxxxxxxxxxxx\n        // 3b. The token starts inside the deletion range, and ends at the same position as the deletion range\n        //                ----------\n        //             xxxxxxxxxxxxx\n        // 3c. The token starts inside the deletion range, and ends after the deletion range\n        //                ------------\n        //             xxxxxxxxxxx\n        //\n        // 4. The token starts after the deletion range\n        //                  -----------\n        //          xxxxxxxx\n        //\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        const deletedLineCount = (endDeltaLine - startDeltaLine);\n        let newTokenCount = 0;\n        let hasDeletedTokens = false;\n        for (let i = 0; i < tokenCount; i++) {\n            const srcOffset = 4 * i;\n            let tokenDeltaLine = tokens[srcOffset];\n            let tokenStartCharacter = tokens[srcOffset + 1];\n            let tokenEndCharacter = tokens[srcOffset + 2];\n            const tokenMetadata = tokens[srcOffset + 3];\n            if (tokenDeltaLine < startDeltaLine || (tokenDeltaLine === startDeltaLine && tokenEndCharacter <= startCharacter)) {\n                // 1a. The token is completely before the deletion range\n                // => nothing to do\n                newTokenCount++;\n                continue;\n            }\n            else if (tokenDeltaLine === startDeltaLine && tokenStartCharacter < startCharacter) {\n                // 1b, 1c, 1d\n                // => the token survives, but it needs to shrink\n                if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n                    // 1d. The token starts before, the deletion range is inside the token\n                    // => the token shrinks by the deletion character count\n                    tokenEndCharacter -= (endCharacter - startCharacter);\n                }\n                else {\n                    // 1b. The token starts before, the deletion range ends after the token\n                    // 1c. The token starts before, the deletion range ends precisely with the token\n                    // => the token shrinks its ending to the deletion start\n                    tokenEndCharacter = startCharacter;\n                }\n            }\n            else if (tokenDeltaLine === startDeltaLine && tokenStartCharacter === startCharacter) {\n                // 2a, 2b, 2c\n                if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n                    // 2c. The token starts at the same position, and ends after the deletion range\n                    // => the token shrinks by the deletion character count\n                    tokenEndCharacter -= (endCharacter - startCharacter);\n                }\n                else {\n                    // 2a. The token starts at the same position, and ends inside the deletion range\n                    // 2b. The token starts at the same position, and ends at the same position as the deletion range\n                    // => the token is deleted\n                    hasDeletedTokens = true;\n                    continue;\n                }\n            }\n            else if (tokenDeltaLine < endDeltaLine || (tokenDeltaLine === endDeltaLine && tokenStartCharacter < endCharacter)) {\n                // 3a, 3b, 3c\n                if (tokenDeltaLine === endDeltaLine && tokenEndCharacter > endCharacter) {\n                    // 3c. The token starts inside the deletion range, and ends after the deletion range\n                    // => the token moves to continue right after the deletion\n                    tokenDeltaLine = startDeltaLine;\n                    tokenStartCharacter = startCharacter;\n                    tokenEndCharacter = tokenStartCharacter + (tokenEndCharacter - endCharacter);\n                }\n                else {\n                    // 3a. The token is inside the deletion range\n                    // 3b. The token starts inside the deletion range, and ends at the same position as the deletion range\n                    // => the token is deleted\n                    hasDeletedTokens = true;\n                    continue;\n                }\n            }\n            else if (tokenDeltaLine > endDeltaLine) {\n                // 4. (partial) The token starts after the deletion range, on a line below...\n                if (deletedLineCount === 0 && !hasDeletedTokens) {\n                    // early stop, there is no need to walk all the tokens and do nothing...\n                    newTokenCount = tokenCount;\n                    break;\n                }\n                tokenDeltaLine -= deletedLineCount;\n            }\n            else if (tokenDeltaLine === endDeltaLine && tokenStartCharacter >= endCharacter) {\n                // 4. (continued) The token starts after the deletion range, on the last line where a deletion occurs\n                if (horizontalShiftForFirstLineTokens && tokenDeltaLine === 0) {\n                    tokenStartCharacter += horizontalShiftForFirstLineTokens;\n                    tokenEndCharacter += horizontalShiftForFirstLineTokens;\n                }\n                tokenDeltaLine -= deletedLineCount;\n                tokenStartCharacter -= (endCharacter - startCharacter);\n                tokenEndCharacter -= (endCharacter - startCharacter);\n            }\n            else {\n                throw new Error(`Not possible!`);\n            }\n            const destOffset = 4 * newTokenCount;\n            tokens[destOffset] = tokenDeltaLine;\n            tokens[destOffset + 1] = tokenStartCharacter;\n            tokens[destOffset + 2] = tokenEndCharacter;\n            tokens[destOffset + 3] = tokenMetadata;\n            newTokenCount++;\n        }\n        this._tokenCount = newTokenCount;\n    }\n    acceptInsertText(deltaLine, character, eolCount, firstLineLength, lastLineLength, firstCharCode) {\n        // Here are the cases I used to think about this:\n        //\n        // 1. The token is completely before the insertion point\n        //            -----------   |\n        // 2. The token ends precisely at the insertion point\n        //            -----------|\n        // 3. The token contains the insertion point\n        //            -----|------\n        // 4. The token starts precisely at the insertion point\n        //            |-----------\n        // 5. The token is completely after the insertion point\n        //            |   -----------\n        //\n        const isInsertingPreciselyOneWordCharacter = (eolCount === 0\n            && firstLineLength === 1\n            && ((firstCharCode >= 48 /* CharCode.Digit0 */ && firstCharCode <= 57 /* CharCode.Digit9 */)\n                || (firstCharCode >= 65 /* CharCode.A */ && firstCharCode <= 90 /* CharCode.Z */)\n                || (firstCharCode >= 97 /* CharCode.a */ && firstCharCode <= 122 /* CharCode.z */)));\n        const tokens = this._tokens;\n        const tokenCount = this._tokenCount;\n        for (let i = 0; i < tokenCount; i++) {\n            const offset = 4 * i;\n            let tokenDeltaLine = tokens[offset];\n            let tokenStartCharacter = tokens[offset + 1];\n            let tokenEndCharacter = tokens[offset + 2];\n            if (tokenDeltaLine < deltaLine || (tokenDeltaLine === deltaLine && tokenEndCharacter < character)) {\n                // 1. The token is completely before the insertion point\n                // => nothing to do\n                continue;\n            }\n            else if (tokenDeltaLine === deltaLine && tokenEndCharacter === character) {\n                // 2. The token ends precisely at the insertion point\n                // => expand the end character only if inserting precisely one character that is a word character\n                if (isInsertingPreciselyOneWordCharacter) {\n                    tokenEndCharacter += 1;\n                }\n                else {\n                    continue;\n                }\n            }\n            else if (tokenDeltaLine === deltaLine && tokenStartCharacter < character && character < tokenEndCharacter) {\n                // 3. The token contains the insertion point\n                if (eolCount === 0) {\n                    // => just expand the end character\n                    tokenEndCharacter += firstLineLength;\n                }\n                else {\n                    // => cut off the token\n                    tokenEndCharacter = character;\n                }\n            }\n            else {\n                // 4. or 5.\n                if (tokenDeltaLine === deltaLine && tokenStartCharacter === character) {\n                    // 4. The token starts precisely at the insertion point\n                    // => grow the token (by keeping its start constant) only if inserting precisely one character that is a word character\n                    // => otherwise behave as in case 5.\n                    if (isInsertingPreciselyOneWordCharacter) {\n                        continue;\n                    }\n                }\n                // => the token must move and keep its size constant\n                if (tokenDeltaLine === deltaLine) {\n                    tokenDeltaLine += eolCount;\n                    // this token is on the line where the insertion is taking place\n                    if (eolCount === 0) {\n                        tokenStartCharacter += firstLineLength;\n                        tokenEndCharacter += firstLineLength;\n                    }\n                    else {\n                        const tokenLength = tokenEndCharacter - tokenStartCharacter;\n                        tokenStartCharacter = lastLineLength + (tokenStartCharacter - character);\n                        tokenEndCharacter = tokenStartCharacter + tokenLength;\n                    }\n                }\n                else {\n                    tokenDeltaLine += eolCount;\n                }\n            }\n            tokens[offset] = tokenDeltaLine;\n            tokens[offset + 1] = tokenStartCharacter;\n            tokens[offset + 2] = tokenEndCharacter;\n        }\n    }\n}\nexport class SparseLineTokens {\n    constructor(tokens) {\n        this._tokens = tokens;\n    }\n    getCount() {\n        return this._tokens.length / 4;\n    }\n    getStartCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 1];\n    }\n    getEndCharacter(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 2];\n    }\n    getMetadata(tokenIndex) {\n        return this._tokens[4 * tokenIndex + 3];\n    }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA,SAASA,QAAQ,QAAQ,qBAAqB;AAC9C,SAASC,KAAK,QAAQ,kBAAkB;AACxC,SAASC,QAAQ,QAAQ,uBAAuB;AAChD;AACA;AACA;AACA,WAAaC,qBAAqB;EAgB9B,SAAAA,sBAAYC,eAAe,EAAEC,MAAM,EAAE;IAAAC,eAAA,OAAAH,qBAAA;IACjC,IAAI,CAACI,gBAAgB,GAAGH,eAAe;IACvC,IAAI,CAACI,OAAO,GAAGH,MAAM;IACrB,IAAI,CAACI,cAAc,GAAG,IAAI,CAACF,gBAAgB,GAAG,IAAI,CAACC,OAAO,CAACE,eAAe,CAAC,CAAC;EAChF;EAAC,OAAAC,YAAA,CAAAR,qBAAA;IAAAS,GAAA;IAAAC,GAAA;IAhBD;AACJ;AACA;IACI,SAAAA,IAAA,EAAsB;MAClB,OAAO,IAAI,CAACN,gBAAgB;IAChC;IACA;AACJ;AACA;EAFI;IAAAK,GAAA;IAAAC,GAAA,EAGA,SAAAA,IAAA,EAAoB;MAChB,OAAO,IAAI,CAACJ,cAAc;IAC9B;EAAC;IAAAG,GAAA;IAAAE,KAAA,EAMD,SAAAC,SAAA,EAAW;MACP,OAAO,IAAI,CAACP,OAAO,CAACO,QAAQ,CAAC,IAAI,CAACR,gBAAgB,CAAC;IACvD;EAAC;IAAAK,GAAA;IAAAE,KAAA,EACD,SAAAE,qBAAA,EAAuB;MACnB,IAAI,CAACP,cAAc,GAAG,IAAI,CAACF,gBAAgB,GAAG,IAAI,CAACC,OAAO,CAACE,eAAe,CAAC,CAAC;IAChF;EAAC;IAAAE,GAAA;IAAAE,KAAA,EACD,SAAAG,QAAA,EAAU;MACN,OAAO,IAAI,CAACT,OAAO,CAACS,OAAO,CAAC,CAAC;IACjC;EAAC;IAAAL,GAAA;IAAAE,KAAA,EACD,SAAAI,cAAcC,UAAU,EAAE;MACtB,IAAI,IAAI,CAACZ,gBAAgB,IAAIY,UAAU,IAAIA,UAAU,IAAI,IAAI,CAACV,cAAc,EAAE;QAC1E,OAAO,IAAI,CAACD,OAAO,CAACU,aAAa,CAACC,UAAU,GAAG,IAAI,CAACZ,gBAAgB,CAAC;MACzE;MACA,OAAO,IAAI;IACf;EAAC;IAAAK,GAAA;IAAAE,KAAA,EACD,SAAAM,SAAA,EAAW;MACP,IAAMC,UAAU,GAAG,IAAI,CAACb,OAAO,CAACY,QAAQ,CAAC,CAAC;MAC1C,IAAI,CAACC,UAAU,EAAE;QACb,OAAOA,UAAU;MACrB;MACA,OAAO,IAAIpB,KAAK,CAAC,IAAI,CAACM,gBAAgB,GAAGc,UAAU,CAACjB,eAAe,EAAEiB,UAAU,CAACC,WAAW,EAAE,IAAI,CAACf,gBAAgB,GAAGc,UAAU,CAACE,aAAa,EAAEF,UAAU,CAACG,SAAS,CAAC;IACxK;EAAC;IAAAZ,GAAA;IAAAE,KAAA,EACD,SAAAW,aAAaC,KAAK,EAAE;MAChB,IAAMC,cAAc,GAAGD,KAAK,CAACtB,eAAe,GAAG,IAAI,CAACG,gBAAgB;MACpE,IAAMqB,YAAY,GAAGF,KAAK,CAACH,aAAa,GAAG,IAAI,CAAChB,gBAAgB;MAChE,IAAI,CAACA,gBAAgB,IAAI,IAAI,CAACC,OAAO,CAACiB,YAAY,CAACE,cAAc,EAAED,KAAK,CAACJ,WAAW,GAAG,CAAC,EAAEM,YAAY,EAAEF,KAAK,CAACF,SAAS,GAAG,CAAC,CAAC;MAC5H,IAAI,CAACR,oBAAoB,CAAC,CAAC;IAC/B;EAAC;IAAAJ,GAAA;IAAAE,KAAA,EACD,SAAAe,MAAMH,KAAK,EAAE;MACT;MACA;MACA;MACA,IAAMC,cAAc,GAAGD,KAAK,CAACtB,eAAe,GAAG,IAAI,CAACG,gBAAgB;MACpE,IAAMqB,YAAY,GAAGF,KAAK,CAACH,aAAa,GAAG,IAAI,CAAChB,gBAAgB;MAChE,IAAAuB,mBAAA,GAA2B,IAAI,CAACtB,OAAO,CAACqB,KAAK,CAACF,cAAc,EAAED,KAAK,CAACJ,WAAW,GAAG,CAAC,EAAEM,YAAY,EAAEF,KAAK,CAACF,SAAS,GAAG,CAAC,CAAC;QAAAO,oBAAA,GAAAC,cAAA,CAAAF,mBAAA;QAAhHG,CAAC,GAAAF,oBAAA;QAAEG,CAAC,GAAAH,oBAAA;QAAEI,UAAU,GAAAJ,oBAAA;MACvB,OAAO,CAAC,IAAI5B,qBAAqB,CAAC,IAAI,CAACI,gBAAgB,EAAE0B,CAAC,CAAC,EAAE,IAAI9B,qBAAqB,CAAC,IAAI,CAACI,gBAAgB,GAAG4B,UAAU,EAAED,CAAC,CAAC,CAAC;IAClI;EAAC;IAAAtB,GAAA;IAAAE,KAAA,EACD,SAAAsB,UAAUV,KAAK,EAAEW,IAAI,EAAE;MACnB,IAAAC,SAAA,GAAoDpC,QAAQ,CAACmC,IAAI,CAAC;QAAAE,UAAA,GAAAP,cAAA,CAAAM,SAAA;QAA3DE,QAAQ,GAAAD,UAAA;QAAEE,eAAe,GAAAF,UAAA;QAAEG,cAAc,GAAAH,UAAA;MAChD,IAAI,CAACI,UAAU,CAACjB,KAAK,EAAEc,QAAQ,EAAEC,eAAe,EAAEC,cAAc,EAAEL,IAAI,CAACO,MAAM,GAAG,CAAC,GAAGP,IAAI,CAACQ,UAAU,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,mBAAmB,CAAC;IACnI;EAAC;IAAAjC,GAAA;IAAAE,KAAA,EACD,SAAA6B,WAAWjB,KAAK,EAAEc,QAAQ,EAAEC,eAAe,EAAEC,cAAc,EAAEI,aAAa,EAAE;MACxE,IAAI,CAACC,kBAAkB,CAACrB,KAAK,CAAC;MAC9B,IAAI,CAACsB,iBAAiB,CAAC,IAAIhD,QAAQ,CAAC0B,KAAK,CAACtB,eAAe,EAAEsB,KAAK,CAACJ,WAAW,CAAC,EAAEkB,QAAQ,EAAEC,eAAe,EAAEC,cAAc,EAAEI,aAAa,CAAC;MACxI,IAAI,CAAC9B,oBAAoB,CAAC,CAAC;IAC/B;EAAC;IAAAJ,GAAA;IAAAE,KAAA,EACD,SAAAiC,mBAAmBrB,KAAK,EAAE;MACtB,IAAIA,KAAK,CAACtB,eAAe,KAAKsB,KAAK,CAACH,aAAa,IAAIG,KAAK,CAACJ,WAAW,KAAKI,KAAK,CAACF,SAAS,EAAE;QACxF;QACA;MACJ;MACA,IAAMyB,cAAc,GAAGvB,KAAK,CAACtB,eAAe,GAAG,IAAI,CAACG,gBAAgB;MACpE,IAAM2C,aAAa,GAAGxB,KAAK,CAACH,aAAa,GAAG,IAAI,CAAChB,gBAAgB;MACjE,IAAI2C,aAAa,GAAG,CAAC,EAAE;QACnB;QACA,IAAMC,iBAAiB,GAAGD,aAAa,GAAGD,cAAc;QACxD,IAAI,CAAC1C,gBAAgB,IAAI4C,iBAAiB;QAC1C;MACJ;MACA,IAAMC,iBAAiB,GAAG,IAAI,CAAC5C,OAAO,CAACE,eAAe,CAAC,CAAC;MACxD,IAAIuC,cAAc,IAAIG,iBAAiB,GAAG,CAAC,EAAE;QACzC;QACA;MACJ;MACA,IAAIH,cAAc,GAAG,CAAC,IAAIC,aAAa,IAAIE,iBAAiB,GAAG,CAAC,EAAE;QAC9D;QACA,IAAI,CAAC7C,gBAAgB,GAAG,CAAC;QACzB,IAAI,CAACC,OAAO,CAAC6C,KAAK,CAAC,CAAC;QACpB;MACJ;MACA,IAAIJ,cAAc,GAAG,CAAC,EAAE;QACpB,IAAMK,aAAa,GAAG,CAACL,cAAc;QACrC,IAAI,CAAC1C,gBAAgB,IAAI+C,aAAa;QACtC,IAAI,CAAC9C,OAAO,CAAC+C,iBAAiB,CAAC7B,KAAK,CAACJ,WAAW,GAAG,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE4B,aAAa,EAAExB,KAAK,CAACF,SAAS,GAAG,CAAC,CAAC;MACnG,CAAC,MACI;QACD,IAAI,CAAChB,OAAO,CAAC+C,iBAAiB,CAAC,CAAC,EAAEN,cAAc,EAAEvB,KAAK,CAACJ,WAAW,GAAG,CAAC,EAAE4B,aAAa,EAAExB,KAAK,CAACF,SAAS,GAAG,CAAC,CAAC;MAChH;IACJ;EAAC;IAAAZ,GAAA;IAAAE,KAAA,EACD,SAAAkC,kBAAkBQ,QAAQ,EAAEhB,QAAQ,EAAEC,eAAe,EAAEC,cAAc,EAAEI,aAAa,EAAE;MAClF,IAAIN,QAAQ,KAAK,CAAC,IAAIC,eAAe,KAAK,CAAC,EAAE;QACzC;QACA;MACJ;MACA,IAAMgB,SAAS,GAAGD,QAAQ,CAACrC,UAAU,GAAG,IAAI,CAACZ,gBAAgB;MAC7D,IAAIkD,SAAS,GAAG,CAAC,EAAE;QACf;QACA,IAAI,CAAClD,gBAAgB,IAAIiC,QAAQ;QACjC;MACJ;MACA,IAAMY,iBAAiB,GAAG,IAAI,CAAC5C,OAAO,CAACE,eAAe,CAAC,CAAC;MACxD,IAAI+C,SAAS,IAAIL,iBAAiB,GAAG,CAAC,EAAE;QACpC;QACA;MACJ;MACA,IAAI,CAAC5C,OAAO,CAACkD,gBAAgB,CAACD,SAAS,EAAED,QAAQ,CAACG,MAAM,GAAG,CAAC,EAAEnB,QAAQ,EAAEC,eAAe,EAAEC,cAAc,EAAEI,aAAa,CAAC;IAC3H;EAAC;IAAAlC,GAAA;IAAAE,KAAA,EApHD,SAAA8C,OAAcxD,eAAe,EAAEC,MAAM,EAAE;MACnC,OAAO,IAAIF,qBAAqB,CAACC,eAAe,EAAE,IAAIyD,4BAA4B,CAACxD,MAAM,CAAC,CAAC;IAC/F;EAAC;AAAA;AAmHJ,IACKwD,4BAA4B;EAC9B,SAAAA,6BAAYxD,MAAM,EAAE;IAAAC,eAAA,OAAAuD,4BAAA;IAChB,IAAI,CAACrD,OAAO,GAAGH,MAAM;IACrB,IAAI,CAACyD,WAAW,GAAGzD,MAAM,CAACuC,MAAM,GAAG,CAAC;EACxC;EAAC,OAAAjC,YAAA,CAAAkD,4BAAA;IAAAjD,GAAA;IAAAE,KAAA,EACD,SAAAC,SAASX,eAAe,EAAE;MACtB,IAAM2D,MAAM,GAAG,EAAE;MACjB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACF,WAAW,EAAEE,CAAC,EAAE,EAAE;QACvCD,MAAM,CAACE,IAAI,KAAAC,MAAA,CAAK,IAAI,CAACC,aAAa,CAACH,CAAC,CAAC,GAAG5D,eAAe,OAAA8D,MAAA,CAAI,IAAI,CAACE,kBAAkB,CAACJ,CAAC,CAAC,OAAAE,MAAA,CAAI,IAAI,CAACG,gBAAgB,CAACL,CAAC,CAAC,MAAG,CAAC;MACzH;MACA,WAAAE,MAAA,CAAWH,MAAM,CAACO,IAAI,CAAC,GAAG,CAAC;IAC/B;EAAC;IAAA1D,GAAA;IAAAE,KAAA,EACD,SAAAJ,gBAAA,EAAkB;MACd,IAAM6D,UAAU,GAAG,IAAI,CAACC,cAAc,CAAC,CAAC;MACxC,IAAID,UAAU,KAAK,CAAC,EAAE;QAClB,OAAO,CAAC,CAAC;MACb;MACA,OAAO,IAAI,CAACJ,aAAa,CAACI,UAAU,GAAG,CAAC,CAAC;IAC7C;EAAC;IAAA3D,GAAA;IAAAE,KAAA,EACD,SAAAM,SAAA,EAAW;MACP,IAAMmD,UAAU,GAAG,IAAI,CAACC,cAAc,CAAC,CAAC;MACxC,IAAID,UAAU,KAAK,CAAC,EAAE;QAClB,OAAO,IAAI;MACf;MACA,IAAME,SAAS,GAAG,IAAI,CAACL,kBAAkB,CAAC,CAAC,CAAC;MAC5C,IAAMM,YAAY,GAAG,IAAI,CAACP,aAAa,CAACI,UAAU,GAAG,CAAC,CAAC;MACvD,IAAMI,OAAO,GAAG,IAAI,CAACN,gBAAgB,CAACE,UAAU,GAAG,CAAC,CAAC;MACrD,OAAO,IAAItE,KAAK,CAAC,CAAC,EAAEwE,SAAS,GAAG,CAAC,EAAEC,YAAY,EAAEC,OAAO,GAAG,CAAC,CAAC;IACjE;EAAC;IAAA/D,GAAA;IAAAE,KAAA,EACD,SAAA0D,eAAA,EAAiB;MACb,OAAO,IAAI,CAACV,WAAW;IAC3B;EAAC;IAAAlD,GAAA;IAAAE,KAAA,EACD,SAAAqD,cAAcS,UAAU,EAAE;MACtB,OAAO,IAAI,CAACpE,OAAO,CAAC,CAAC,GAAGoE,UAAU,CAAC;IACvC;EAAC;IAAAhE,GAAA;IAAAE,KAAA,EACD,SAAAsD,mBAAmBQ,UAAU,EAAE;MAC3B,OAAO,IAAI,CAACpE,OAAO,CAAC,CAAC,GAAGoE,UAAU,GAAG,CAAC,CAAC;IAC3C;EAAC;IAAAhE,GAAA;IAAAE,KAAA,EACD,SAAAuD,iBAAiBO,UAAU,EAAE;MACzB,OAAO,IAAI,CAACpE,OAAO,CAAC,CAAC,GAAGoE,UAAU,GAAG,CAAC,CAAC;IAC3C;EAAC;IAAAhE,GAAA;IAAAE,KAAA,EACD,SAAAG,QAAA,EAAU;MACN,OAAQ,IAAI,CAACuD,cAAc,CAAC,CAAC,KAAK,CAAC;IACvC;EAAC;IAAA5D,GAAA;IAAAE,KAAA,EACD,SAAAI,cAAc2D,SAAS,EAAE;MACrB,IAAIC,GAAG,GAAG,CAAC;MACX,IAAIC,IAAI,GAAG,IAAI,CAACP,cAAc,CAAC,CAAC,GAAG,CAAC;MACpC,OAAOM,GAAG,GAAGC,IAAI,EAAE;QACf,IAAMC,GAAG,GAAGF,GAAG,GAAGG,IAAI,CAACC,KAAK,CAAC,CAACH,IAAI,GAAGD,GAAG,IAAI,CAAC,CAAC;QAC9C,IAAMK,YAAY,GAAG,IAAI,CAAChB,aAAa,CAACa,GAAG,CAAC;QAC5C,IAAIG,YAAY,GAAGN,SAAS,EAAE;UAC1BC,GAAG,GAAGE,GAAG,GAAG,CAAC;QACjB,CAAC,MACI,IAAIG,YAAY,GAAGN,SAAS,EAAE;UAC/BE,IAAI,GAAGC,GAAG,GAAG,CAAC;QAClB,CAAC,MACI;UACD,IAAII,GAAG,GAAGJ,GAAG;UACb,OAAOI,GAAG,GAAGN,GAAG,IAAI,IAAI,CAACX,aAAa,CAACiB,GAAG,GAAG,CAAC,CAAC,KAAKP,SAAS,EAAE;YAC3DO,GAAG,EAAE;UACT;UACA,IAAIC,GAAG,GAAGL,GAAG;UACb,OAAOK,GAAG,GAAGN,IAAI,IAAI,IAAI,CAACZ,aAAa,CAACkB,GAAG,GAAG,CAAC,CAAC,KAAKR,SAAS,EAAE;YAC5DQ,GAAG,EAAE;UACT;UACA,OAAO,IAAIC,gBAAgB,CAAC,IAAI,CAAC9E,OAAO,CAAC+E,QAAQ,CAAC,CAAC,GAAGH,GAAG,EAAE,CAAC,GAAGC,GAAG,GAAG,CAAC,CAAC,CAAC;QAC5E;MACJ;MACA,IAAI,IAAI,CAAClB,aAAa,CAACW,GAAG,CAAC,KAAKD,SAAS,EAAE;QACvC,OAAO,IAAIS,gBAAgB,CAAC,IAAI,CAAC9E,OAAO,CAAC+E,QAAQ,CAAC,CAAC,GAAGT,GAAG,EAAE,CAAC,GAAGA,GAAG,GAAG,CAAC,CAAC,CAAC;MAC5E;MACA,OAAO,IAAI;IACf;EAAC;IAAAlE,GAAA;IAAAE,KAAA,EACD,SAAAuC,MAAA,EAAQ;MACJ,IAAI,CAACS,WAAW,GAAG,CAAC;IACxB;EAAC;IAAAlD,GAAA;IAAAE,KAAA,EACD,SAAAW,aAAa+D,cAAc,EAAEf,SAAS,EAAEgB,YAAY,EAAEd,OAAO,EAAE;MAC3D,IAAMtE,MAAM,GAAG,IAAI,CAACG,OAAO;MAC3B,IAAM+D,UAAU,GAAG,IAAI,CAACT,WAAW;MACnC,IAAI4B,aAAa,GAAG,CAAC;MACrB,IAAIC,gBAAgB,GAAG,KAAK;MAC5B,IAAIC,cAAc,GAAG,CAAC;MACtB,KAAK,IAAI5B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGO,UAAU,EAAEP,CAAC,EAAE,EAAE;QACjC,IAAM6B,SAAS,GAAG,CAAC,GAAG7B,CAAC;QACvB,IAAM8B,cAAc,GAAGzF,MAAM,CAACwF,SAAS,CAAC;QACxC,IAAME,mBAAmB,GAAG1F,MAAM,CAACwF,SAAS,GAAG,CAAC,CAAC;QACjD,IAAMG,iBAAiB,GAAG3F,MAAM,CAACwF,SAAS,GAAG,CAAC,CAAC;QAC/C,IAAMI,aAAa,GAAG5F,MAAM,CAACwF,SAAS,GAAG,CAAC,CAAC;QAC3C,IAAI,CAACC,cAAc,GAAGN,cAAc,IAAKM,cAAc,KAAKN,cAAc,IAAIQ,iBAAiB,IAAIvB,SAAU,MACrGqB,cAAc,GAAGL,YAAY,IAAKK,cAAc,KAAKL,YAAY,IAAIM,mBAAmB,IAAIpB,OAAQ,CAAC,EAAE;UAC3GgB,gBAAgB,GAAG,IAAI;QAC3B,CAAC,MACI;UACD,IAAID,aAAa,KAAK,CAAC,EAAE;YACrBE,cAAc,GAAGE,cAAc;UACnC;UACA,IAAIH,gBAAgB,EAAE;YAClB;YACA,IAAMO,UAAU,GAAG,CAAC,GAAGR,aAAa;YACpCrF,MAAM,CAAC6F,UAAU,CAAC,GAAGJ,cAAc,GAAGF,cAAc;YACpDvF,MAAM,CAAC6F,UAAU,GAAG,CAAC,CAAC,GAAGH,mBAAmB;YAC5C1F,MAAM,CAAC6F,UAAU,GAAG,CAAC,CAAC,GAAGF,iBAAiB;YAC1C3F,MAAM,CAAC6F,UAAU,GAAG,CAAC,CAAC,GAAGD,aAAa;UAC1C;UACAP,aAAa,EAAE;QACnB;MACJ;MACA,IAAI,CAAC5B,WAAW,GAAG4B,aAAa;MAChC,OAAOE,cAAc;IACzB;EAAC;IAAAhF,GAAA;IAAAE,KAAA,EACD,SAAAe,MAAM2D,cAAc,EAAEf,SAAS,EAAEgB,YAAY,EAAEd,OAAO,EAAE;MACpD,IAAMtE,MAAM,GAAG,IAAI,CAACG,OAAO;MAC3B,IAAM+D,UAAU,GAAG,IAAI,CAACT,WAAW;MACnC,IAAMqC,OAAO,GAAG,EAAE;MAClB,IAAMC,OAAO,GAAG,EAAE;MAClB,IAAIC,UAAU,GAAGF,OAAO;MACxB,IAAID,UAAU,GAAG,CAAC;MAClB,IAAII,kBAAkB,GAAG,CAAC;MAC1B,KAAK,IAAItC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGO,UAAU,EAAEP,CAAC,EAAE,EAAE;QACjC,IAAM6B,SAAS,GAAG,CAAC,GAAG7B,CAAC;QACvB,IAAM8B,cAAc,GAAGzF,MAAM,CAACwF,SAAS,CAAC;QACxC,IAAME,mBAAmB,GAAG1F,MAAM,CAACwF,SAAS,GAAG,CAAC,CAAC;QACjD,IAAMG,iBAAiB,GAAG3F,MAAM,CAACwF,SAAS,GAAG,CAAC,CAAC;QAC/C,IAAMI,aAAa,GAAG5F,MAAM,CAACwF,SAAS,GAAG,CAAC,CAAC;QAC3C,IAAKC,cAAc,GAAGN,cAAc,IAAKM,cAAc,KAAKN,cAAc,IAAIQ,iBAAiB,IAAIvB,SAAU,EAAG;UAC5G,IAAKqB,cAAc,GAAGL,YAAY,IAAKK,cAAc,KAAKL,YAAY,IAAIM,mBAAmB,IAAIpB,OAAQ,EAAG;YACxG;YACA;UACJ,CAAC,MACI;YACD;YACA,IAAI0B,UAAU,KAAKD,OAAO,EAAE;cACxB;cACAC,UAAU,GAAGD,OAAO;cACpBF,UAAU,GAAG,CAAC;cACdI,kBAAkB,GAAGR,cAAc;YACvC;UACJ;QACJ;QACAO,UAAU,CAACH,UAAU,EAAE,CAAC,GAAGJ,cAAc,GAAGQ,kBAAkB;QAC9DD,UAAU,CAACH,UAAU,EAAE,CAAC,GAAGH,mBAAmB;QAC9CM,UAAU,CAACH,UAAU,EAAE,CAAC,GAAGF,iBAAiB;QAC5CK,UAAU,CAACH,UAAU,EAAE,CAAC,GAAGD,aAAa;MAC5C;MACA,OAAO,CAAC,IAAIpC,4BAA4B,CAAC,IAAI0C,WAAW,CAACJ,OAAO,CAAC,CAAC,EAAE,IAAItC,4BAA4B,CAAC,IAAI0C,WAAW,CAACH,OAAO,CAAC,CAAC,EAAEE,kBAAkB,CAAC;IACvJ;EAAC;IAAA1F,GAAA;IAAAE,KAAA,EACD,SAAAyC,kBAAkBiD,iCAAiC,EAAEhB,cAAc,EAAEiB,cAAc,EAAEhB,YAAY,EAAEiB,YAAY,EAAE;MAC7G;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA,IAAMrG,MAAM,GAAG,IAAI,CAACG,OAAO;MAC3B,IAAM+D,UAAU,GAAG,IAAI,CAACT,WAAW;MACnC,IAAM6C,gBAAgB,GAAIlB,YAAY,GAAGD,cAAe;MACxD,IAAIE,aAAa,GAAG,CAAC;MACrB,IAAIC,gBAAgB,GAAG,KAAK;MAC5B,KAAK,IAAI3B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGO,UAAU,EAAEP,CAAC,EAAE,EAAE;QACjC,IAAM6B,SAAS,GAAG,CAAC,GAAG7B,CAAC;QACvB,IAAI8B,cAAc,GAAGzF,MAAM,CAACwF,SAAS,CAAC;QACtC,IAAIE,mBAAmB,GAAG1F,MAAM,CAACwF,SAAS,GAAG,CAAC,CAAC;QAC/C,IAAIG,iBAAiB,GAAG3F,MAAM,CAACwF,SAAS,GAAG,CAAC,CAAC;QAC7C,IAAMI,aAAa,GAAG5F,MAAM,CAACwF,SAAS,GAAG,CAAC,CAAC;QAC3C,IAAIC,cAAc,GAAGN,cAAc,IAAKM,cAAc,KAAKN,cAAc,IAAIQ,iBAAiB,IAAIS,cAAe,EAAE;UAC/G;UACA;UACAf,aAAa,EAAE;UACf;QACJ,CAAC,MACI,IAAII,cAAc,KAAKN,cAAc,IAAIO,mBAAmB,GAAGU,cAAc,EAAE;UAChF;UACA;UACA,IAAIX,cAAc,KAAKL,YAAY,IAAIO,iBAAiB,GAAGU,YAAY,EAAE;YACrE;YACA;YACAV,iBAAiB,IAAKU,YAAY,GAAGD,cAAe;UACxD,CAAC,MACI;YACD;YACA;YACA;YACAT,iBAAiB,GAAGS,cAAc;UACtC;QACJ,CAAC,MACI,IAAIX,cAAc,KAAKN,cAAc,IAAIO,mBAAmB,KAAKU,cAAc,EAAE;UAClF;UACA,IAAIX,cAAc,KAAKL,YAAY,IAAIO,iBAAiB,GAAGU,YAAY,EAAE;YACrE;YACA;YACAV,iBAAiB,IAAKU,YAAY,GAAGD,cAAe;UACxD,CAAC,MACI;YACD;YACA;YACA;YACAd,gBAAgB,GAAG,IAAI;YACvB;UACJ;QACJ,CAAC,MACI,IAAIG,cAAc,GAAGL,YAAY,IAAKK,cAAc,KAAKL,YAAY,IAAIM,mBAAmB,GAAGW,YAAa,EAAE;UAC/G;UACA,IAAIZ,cAAc,KAAKL,YAAY,IAAIO,iBAAiB,GAAGU,YAAY,EAAE;YACrE;YACA;YACAZ,cAAc,GAAGN,cAAc;YAC/BO,mBAAmB,GAAGU,cAAc;YACpCT,iBAAiB,GAAGD,mBAAmB,IAAIC,iBAAiB,GAAGU,YAAY,CAAC;UAChF,CAAC,MACI;YACD;YACA;YACA;YACAf,gBAAgB,GAAG,IAAI;YACvB;UACJ;QACJ,CAAC,MACI,IAAIG,cAAc,GAAGL,YAAY,EAAE;UACpC;UACA,IAAIkB,gBAAgB,KAAK,CAAC,IAAI,CAAChB,gBAAgB,EAAE;YAC7C;YACAD,aAAa,GAAGnB,UAAU;YAC1B;UACJ;UACAuB,cAAc,IAAIa,gBAAgB;QACtC,CAAC,MACI,IAAIb,cAAc,KAAKL,YAAY,IAAIM,mBAAmB,IAAIW,YAAY,EAAE;UAC7E;UACA,IAAIF,iCAAiC,IAAIV,cAAc,KAAK,CAAC,EAAE;YAC3DC,mBAAmB,IAAIS,iCAAiC;YACxDR,iBAAiB,IAAIQ,iCAAiC;UAC1D;UACAV,cAAc,IAAIa,gBAAgB;UAClCZ,mBAAmB,IAAKW,YAAY,GAAGD,cAAe;UACtDT,iBAAiB,IAAKU,YAAY,GAAGD,cAAe;QACxD,CAAC,MACI;UACD,MAAM,IAAIG,KAAK,gBAAgB,CAAC;QACpC;QACA,IAAMV,UAAU,GAAG,CAAC,GAAGR,aAAa;QACpCrF,MAAM,CAAC6F,UAAU,CAAC,GAAGJ,cAAc;QACnCzF,MAAM,CAAC6F,UAAU,GAAG,CAAC,CAAC,GAAGH,mBAAmB;QAC5C1F,MAAM,CAAC6F,UAAU,GAAG,CAAC,CAAC,GAAGF,iBAAiB;QAC1C3F,MAAM,CAAC6F,UAAU,GAAG,CAAC,CAAC,GAAGD,aAAa;QACtCP,aAAa,EAAE;MACnB;MACA,IAAI,CAAC5B,WAAW,GAAG4B,aAAa;IACpC;EAAC;IAAA9E,GAAA;IAAAE,KAAA,EACD,SAAA4C,iBAAiBmB,SAAS,EAAEgC,SAAS,EAAErE,QAAQ,EAAEC,eAAe,EAAEC,cAAc,EAAEI,aAAa,EAAE;MAC7F;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA,IAAMgE,oCAAoC,GAAItE,QAAQ,KAAK,CAAC,IACrDC,eAAe,KAAK,CAAC,KACnBK,aAAa,IAAI,EAAE,CAAC,yBAAyBA,aAAa,IAAI,EAAE,CAAC,yBAC9DA,aAAa,IAAI,EAAE,CAAC,oBAAoBA,aAAa,IAAI,EAAE,CAAC,gBAAiB,IAC7EA,aAAa,IAAI,EAAE,CAAC,oBAAoBA,aAAa,IAAI,GAAG,CAAC,gBAAiB,CAAE;MAC5F,IAAMzC,MAAM,GAAG,IAAI,CAACG,OAAO;MAC3B,IAAM+D,UAAU,GAAG,IAAI,CAACT,WAAW;MACnC,KAAK,IAAIE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGO,UAAU,EAAEP,CAAC,EAAE,EAAE;QACjC,IAAM+C,MAAM,GAAG,CAAC,GAAG/C,CAAC;QACpB,IAAI8B,cAAc,GAAGzF,MAAM,CAAC0G,MAAM,CAAC;QACnC,IAAIhB,mBAAmB,GAAG1F,MAAM,CAAC0G,MAAM,GAAG,CAAC,CAAC;QAC5C,IAAIf,iBAAiB,GAAG3F,MAAM,CAAC0G,MAAM,GAAG,CAAC,CAAC;QAC1C,IAAIjB,cAAc,GAAGjB,SAAS,IAAKiB,cAAc,KAAKjB,SAAS,IAAImB,iBAAiB,GAAGa,SAAU,EAAE;UAC/F;UACA;UACA;QACJ,CAAC,MACI,IAAIf,cAAc,KAAKjB,SAAS,IAAImB,iBAAiB,KAAKa,SAAS,EAAE;UACtE;UACA;UACA,IAAIC,oCAAoC,EAAE;YACtCd,iBAAiB,IAAI,CAAC;UAC1B,CAAC,MACI;YACD;UACJ;QACJ,CAAC,MACI,IAAIF,cAAc,KAAKjB,SAAS,IAAIkB,mBAAmB,GAAGc,SAAS,IAAIA,SAAS,GAAGb,iBAAiB,EAAE;UACvG;UACA,IAAIxD,QAAQ,KAAK,CAAC,EAAE;YAChB;YACAwD,iBAAiB,IAAIvD,eAAe;UACxC,CAAC,MACI;YACD;YACAuD,iBAAiB,GAAGa,SAAS;UACjC;QACJ,CAAC,MACI;UACD;UACA,IAAIf,cAAc,KAAKjB,SAAS,IAAIkB,mBAAmB,KAAKc,SAAS,EAAE;YACnE;YACA;YACA;YACA,IAAIC,oCAAoC,EAAE;cACtC;YACJ;UACJ;UACA;UACA,IAAIhB,cAAc,KAAKjB,SAAS,EAAE;YAC9BiB,cAAc,IAAItD,QAAQ;YAC1B;YACA,IAAIA,QAAQ,KAAK,CAAC,EAAE;cAChBuD,mBAAmB,IAAItD,eAAe;cACtCuD,iBAAiB,IAAIvD,eAAe;YACxC,CAAC,MACI;cACD,IAAMuE,WAAW,GAAGhB,iBAAiB,GAAGD,mBAAmB;cAC3DA,mBAAmB,GAAGrD,cAAc,IAAIqD,mBAAmB,GAAGc,SAAS,CAAC;cACxEb,iBAAiB,GAAGD,mBAAmB,GAAGiB,WAAW;YACzD;UACJ,CAAC,MACI;YACDlB,cAAc,IAAItD,QAAQ;UAC9B;QACJ;QACAnC,MAAM,CAAC0G,MAAM,CAAC,GAAGjB,cAAc;QAC/BzF,MAAM,CAAC0G,MAAM,GAAG,CAAC,CAAC,GAAGhB,mBAAmB;QACxC1F,MAAM,CAAC0G,MAAM,GAAG,CAAC,CAAC,GAAGf,iBAAiB;MAC1C;IACJ;EAAC;AAAA;AAEL,WAAaV,gBAAgB;EACzB,SAAAA,iBAAYjF,MAAM,EAAE;IAAAC,eAAA,OAAAgF,gBAAA;IAChB,IAAI,CAAC9E,OAAO,GAAGH,MAAM;EACzB;EAAC,OAAAM,YAAA,CAAA2E,gBAAA;IAAA1E,GAAA;IAAAE,KAAA,EACD,SAAAmG,SAAA,EAAW;MACP,OAAO,IAAI,CAACzG,OAAO,CAACoC,MAAM,GAAG,CAAC;IAClC;EAAC;IAAAhC,GAAA;IAAAE,KAAA,EACD,SAAAoG,kBAAkBtC,UAAU,EAAE;MAC1B,OAAO,IAAI,CAACpE,OAAO,CAAC,CAAC,GAAGoE,UAAU,GAAG,CAAC,CAAC;IAC3C;EAAC;IAAAhE,GAAA;IAAAE,KAAA,EACD,SAAAqG,gBAAgBvC,UAAU,EAAE;MACxB,OAAO,IAAI,CAACpE,OAAO,CAAC,CAAC,GAAGoE,UAAU,GAAG,CAAC,CAAC;IAC3C;EAAC;IAAAhE,GAAA;IAAAE,KAAA,EACD,SAAAsG,YAAYxC,UAAU,EAAE;MACpB,OAAO,IAAI,CAACpE,OAAO,CAAC,CAAC,GAAGoE,UAAU,GAAG,CAAC,CAAC;IAC3C;EAAC;AAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}